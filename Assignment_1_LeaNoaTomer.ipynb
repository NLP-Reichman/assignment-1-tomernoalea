{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "FECp14-d_F2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NLP-Reichman/assignment_1.git\n",
        "!mv assignment_1/data data\n",
        "!rm assignment_1/ -r"
      ],
      "metadata": {
        "id": "za-DgcYB_IQx",
        "outputId": "a7c31492-533c-4c8c-8499-b5d5bf0ba477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment_1'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 150 (delta 42), reused 33 (delta 25), pack-reused 92\u001b[K\n",
            "Receiving objects: 100% (150/150), 6.79 MiB | 17.77 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "mv: cannot move 'assignment_1/data' to 'data/data': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this assignment you will be creating tools for learning and testing language models. The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n",
        "The relevant files are under the data folder:\n",
        "\n",
        "- en.csv (or the equivalent JSON file)\n",
        "- es.csv (or the equivalent JSON file)\n",
        "- fr.csv (or the equivalent JSON file)\n",
        "- in.csv (or the equivalent JSON file)\n",
        "- it.csv (or the equivalent JSON file)\n",
        "- nl.csv (or the equivalent JSON file)\n",
        "- pt.csv (or the equivalent JSON file)\n",
        "- tl.csv (or the equivalent JSON file)"
      ],
      "metadata": {
        "id": "0i2bOXTB8Dvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "1u1qR7iaq_GU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import collections\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "IHN0tWTurwkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "Implement the function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. Our token definition is a single UTF-8 encoded character. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data.\n",
        "\n",
        "Note - do NOT lowercase the sentences in whi HW."
      ],
      "metadata": {
        "id": "i56aKA0K8adr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tweet_texts(file_path: str) -> list[str]:\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "    data = json.loads(content)\n",
        "    tweet_texts = data['tweet_text'].values()\n",
        "\n",
        "  return tweet_texts\n",
        "\n",
        "\n",
        "def preprocess() -> list[str]:\n",
        "  '''\n",
        "  Return a list of characters, representing the shared vocabulary of all languages\n",
        "  '''\n",
        "  vocabulary = set()\n",
        "\n",
        "  for filename in os.listdir('/content/data'):\n",
        "        file_path = os.path.join('/content/data', filename)\n",
        "        if file_path.endswith('.json'):\n",
        "          tweet_texts = get_tweet_texts(file_path)\n",
        "          for tweet in tweet_texts:\n",
        "              vocabulary.update(tweet)\n",
        "\n",
        "  vocabulary.update(['א', 'ת'])\n",
        "\n",
        "  return list(vocabulary)\n",
        "\n",
        "print(preprocess())"
      ],
      "metadata": {
        "id": "ws_5u7vRrg0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0d4782-b09a-431b-9d8b-3af9b7bb4e48"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['슈', '┻', '과', '🍵', '↛', '😆', '⋅', '▶', '🔘', '📊', '影', '♩', '헌', '맨', '😨', '📻', '♡', '터', '́', '🤙', '^', '挨', '午', '💃', '†', '✊', '◆', '˘', 'ｐ', '©', '🙏', '제', '\\u2066', '½', '🎆', '헨', '🐮', '❥', '］', '📌', '룰', '🌅', 'ˡ', '世', 'М', '￼', '엣', '༻', 'う', '🇭', '🔛', '🈵', 'ถ', '연', '🌒', '“', '❞', '😜', '那', '💢', '🎯', '中', '🐭', '🚨', '❁', '✳', '🏔', 'ｚ', 'น', '💜', '윤', '본', 'Ò', '뱀', '유', '🐦', '🚗', '🌽', '갓', '🌎', '╴', '🏙', '현', 'н', '🐜', '◑', 'ي', 'H', '♻', 'ุ', '🤑', '🐢', '🥅', '😂', '🔵', '🍴', '✴', 'ᵗ', '🐸', '♍', '☓', 'v', '🇾', '🎥', 'ω', 'ท', 'A', '²', '✶', '🔹', '🔁', 'º', 'ゴ', '🍽', 'q', '💀', '🛴', '🤞', '🐣', 'ю', '🙌', '先', '버', '⛄', '💑', '싸', '🐟', 'u', 'υ', '🌍', '🍦', 'ë', '文', '🏆', '🈷', '🅰', '/', 'ね', '}', 'く', '🙉', '画', 'ㅏ', 'Ｌ', '👆', 'п', '😘', '▔', '두', 'ร', '드', '•', '༎', '➌', '사', '파', 'Œ', '☆', '🐝', '🌥', 'г', '⸅', 'ᵛ', 'ย', '姿', '잘', '🍯', 'せ', 'ة', '⁷', '🚼', '⛳', '🏴', '😫', 'い', '👺', '⏰', '📬', 'ศ', 'W', '▼', '🇧', 'Р', '🍪', 'ᵖ', '☑', '온', '😢', '👖', '🥂', 'و', '👂', '🖼', '😦', '👓', '⚖', '넷', 'ノ', '🏟', '랑', '🍝', '服', '🍥', '🤳', '·', '→', 'Á', '«', '🆘', '🔔', '♋', '✖', '👏', 'ユ', '🚲', '👄', '🤖', '◕', '💗', '🕪', '╝', '🔃', '🐔', '벅', '민', '§', '🤡', '🎢', '💩', '🥐', '💍', 'ه', '🚶', 'ग', 'س', '그', '랜', 'ط', 'б', '⚕', '션', '♏', 'に', '🍋', '승', '💤', '🕷', '💏', '儿', '｡', '➋', '쩜', 'ヒ', '︵', '☛', 'な', '👲', '격', '̥', '🚵', '🌴', '👞', '타', '💦', '̮', '가', '͡', 'ү', '븐', '👪', '🆒', 'ｃ', '📛', '➰', '˛', '🚔', '🥄', '🙇', '△', 'Í', 'Ş', 'í', '≦', '☞', '🌫', '好', '😃', '네', '💔', '🌪', 'ᵃ', '≤', 'خ', '✍', 'ｅ', '패', '👵', '🍏', 'ر', 'А', '🤚', '빅', 'с', '\\\\', '̀', '🐷', '◽', '🌻', '🍱', '�', '송', '📷', 'ド', '샤', '🍼', '✵', '《', 'ƒ', '➍', 'ل', '❈', '👭', '▣', 'ʖ', '╭', '🏳', 'ม', '😏', 'ō', '당', '👌', '⒏', 'ث', '🤢', '🥀', '2', 'Ｎ', '📼', '경', '츠', 'Ｋ', 'स', '🥔', '🎤', '❌', '🅾', '”', '😰', '☰', '●', '🎦', 'c', '撃', '🌼', 'พ', '☔', '🕺', '終', '요', '▿', '렛', '🏠', '🏃', '∀', '¶', '🐽', '╱', '🗝', '√', '💁', '검', 'ั', '🎠', '상', 'セ', '🍖', 'ك', '식', 'K', '🌿', '🍤', '⚾', '💟', '❎', '🎇', '🇯', '🤣', 'ş', '😅', 'Ñ', '🍾', '〜', '👧', '🃏', '텐', '😼', '👶', '糟', '🤗', '😀', '💭', '🍎', 'メ', '해', '✅', '🎈', '✡', '＊', '💣', '►', '┓', 'Н', '🇷', '͜', '🔴', '외', 'み', '😒', '卒', '̃', '\\x80', 'ｙ', '✂', '💿', '🔽', '😈', '⒍', '단', '🐑', '탄', '찰', '💌', '⠀', 'ี', '-', '🐼', 'à', '🇿', '락', '피', 'ä', '🌺', '코', '間', '종', '🐓', 'ຶ', '🍌', '👕', 'ó', '📰', '気', '🦉', '🎉', 'û', 'े', '슬', '人', '🙂', '😹', '🍚', 'è', '🍩', '🏚', '⬅', '이', '🐘', 'E', '+', 'た', '🎗', '🚫', '림', '🍷', 'r', '↯', '』', '구', '벨', '🔙', 'Ｒ', '💆', '6', '📽', '재', 'บ', '😁', '🔑', 'ㅅ', 'آ', '☠', '👣', '🏒', '☼', '➟', 'し', '👸', '\"', '🚀', 'ㅈ', '☝', '4', 'L', 'Ｆ', '토', '🐿', '♣', '🚌', '~', '増', '👎', '🔜', 'א', '🐬', '🐒', '‰', '⌛', '👼', 'i', 'É', 'Ғ', '🕤', '✧', 'Ф', '📏', '┗', '＃', '👮', '뷔', '┛', 'ป', '◎', '.', 'ʕ', ',', ';', '🐖', '🖒', '☮', '💝', '歳', 'わ', '拶', 'é', 'ひ', '्', '╚', '미', '🎸', 'ª', '＂', '🐊', 'ｗ', '0', '☁', '📯', '🦁', '혁', '🍔', '分', 'ว', '\\u2069', '⛅', '✁', 'Ｖ', 'ㅜ', 'z', '탑', '🙆', '🍻', 'ń', '∞', 'ォ', '🐲', '➤', '🐕', '🌆', 'm', 'ی', '프', '╯', '・', '🌜', 'V', 'Ç', '\\x9d', '込', '니', '℅', '¡', '🙊', '🙀', '🚇', '🎻', 'b', '▕', '세', '🎱', '마', '\\u2067', 'â', '보', '‿', 'ㅤ', '🔨', '😠', '魏', '🐱', '🔓', '?', '🕵', 'づ', '🆙', '👥', '⌣', '금', '💮', '포', 'Ω', '🍨', 'ง', '🔐', '業', '석', '🎫', '|', '🔻', '최', '🅱', '선', '🦑', '🏢', '⤵', '동', '👈', '🐩', '훈', 'テ', '🍺', 'C', 'ｕ', 'ⓘ', '🌸', '※', '에', '백', '방', 'ら', '👙', 'î', '☾', '😱', 'か', '🦇', '。', '▦', '콘', '📀', '😷', '🌲', '⭐', '★', 'ツ', '🇲', '☄', '🕯', '🗳', '⏳', 'S', '🌃', '🍀', '◾', '🐯', '♐', '┆', '📧', 'Ｅ', '&', '〆', '핸', '누', '主', '😯', '😭', '😻', '付', '롱', '👊', 'ė', '┏', '나', 'ᶜ', '➙', '☚', '🔩', 'ᵒ', '장', 'Ｈ', 'ف', '핑', '🤥', '🏹', '🌄', 'ヽ', 'Ｍ', '🎵', 'в', 'ｉ', 'オ', '🍜', '╦', '🌓', 'て', '╬', '천', '）', 'Δ', '》', '🎞', '👱', 'Ü', '🤠', '允', '샵', '¸', 'ー', '🥞', 'р', '🌚', '😎', '🎋', '⛪', '더', 'ﾉ', '刹', 'ａ', '❝', '🌊', '̈', '콤', '制', '≧', '✌', '繋', 'G', 'я', '🎓', '–', '\\u200d', '👯', '手', '◈', '🎒', '🌙', '🙎', '☹', '\\u200a', '예', '̯', '료', 'П', '🐂', '🍑', 'ᵍ', '↚', '🔂', 'Ⓜ', '👰', '🦃', '🤒', 'Ｑ', '👦', '🇵', '™', '✭', '😵', 'จ', '♪', '🎩', '🌞', '🚻', '💖', '🛳', '🗣', 'る', '📓', '📦', '🤓', 'ا', 'À', '！', '🍞', '»', '❄', 'ع', '☉', '📸', '互', 'ᵈ', '인', 'と', '🆓', '🔋', '🎿', '↩', '걸', '➖', 'ⓦ', '💕', '호', '💬', '런', 'ก', '!', '게', '🗽', '‼', '⚒', '[', '⛩', 'h', '😡', '花', '🐹', '🍁', '➜', '💸', '😩', '🌾', '…', '진', '🚴', 'Š', 'О', '┃', '브', '매', '💙', '야', '고', '의', '👤', '🔸', 'キ', 'ʷ', '☀', 'ｌ', '카', 'ㅠ', '👹', '직', '３', 'Я', '菜', '😞', '相', '📡', '歌', '風', '\\u31ef', '◡', '╗', '🐎', '【', '🍒', '˚', 'İ', '🍅', 'n', '✃', 'ｂ', 'Ô', ')', 'れ', '↔', 'り', '🗾', '🐄', ' ', '☃', '✏', 'チ', '真', '💯', '😮', '$', '🎟', '>', 'ʸ', '˖', '瞬', '생', '℃', '💰', '🌝', '🐾', 'Ì', '🤛', '📚', '🔶', 'パ', 'ㅣ', '임', 'к', '🏰', '키', '신', '🔪', '🎁', '🎾', 'I', ':', '📢', '🛀', 'ﷻ', '5', '셔', '철', '어', '＿', '🎺', '➗', '🌌', '✩', '법', 'サ', 'т', '👁', 'र', '헤', '크', '🐐', '💨', 'ı', 'Ａ', '\\xad', 'ょ', '잭', 'g', '👅', 'з', 'Õ', '1', '∵', '🕌', '7', '💳', 'ʳ', '🚈', '💼', '▪', '➠', '時', 'ج', '⊙', '🥁', 'ｇ', '안', '🕒', 'ブ', '⒐', '😊', 'ق', '램', '像', '🆑', '🍫', '↺', '🛃', '🐥', 'プ', 'อ', 'ジ', 'ð', '〰', '⌚', '전', '💈', 'ュ', 'Ú', 'Ｕ', '🙋', 'ぜ', 'T', '┄', 'ᵉ', 'ｘ', '🌱', 'ะ', '실', 'á', '🚑', '♯', '×', 'ภ', '➔', '🤔', '👑', '☪', '김', '🤴', 'Θ', '\\U000fe4e6', 'U', 'Ｐ', 'ن', '남', '😸', 'Ë', 'प', '🛩', 'D', '🇺', '💎', '*', 'ᶦ', '映', 'ᙓ', '😓', 'ビ', '写', 'ピ', '①', 'ｑ', '하', '형', 'ئ', 'j', '%', 'ス', '🚦', '🎧', 'Ｃ', '🇫', '入', '🎰', '\\x92', '😚', '¤', '🔮', '🚣', 'д', '오', '👋', 'ク', 'ö', '⚓', 'ת', '↓', '🐞', '노', '🏄', '💂', '▝', 'き', '🌟', '⁉', '널', 'ì', 'Ｓ', '💉', 'P', '몬', '😕', '↕', '🤷', '💶', '🎶', '한', '랙', 'F', '지', '―', '🥃', '🍿', '洸', '動', 'õ', 'ᶰ', '▽', '대', '─', '›', '﹪', '力', '📩', '️', '๑', '🚧', '🐧', '┳', '트', '봉', '🏇', '초', '🌹', '🏡', '🚙', '박', 'R', '역', '🎅', '≥', '릉', '∆', '機', '💪', '’', '🌨', '༺', '😿', '♛', '撮', '෴', 'd', '🏅', '⏱', '🕛', 'ム', '◻', '💘', ']', 'ᴬ', '둑', 'レ', '주', '👐', '🚓', '林', '🗻', 'ᵘ', '⒎', '®', '⃣', '通', 'ü', '➛', '━', '✰', '🐁', '投', '🔅', '☽', 'の', '⸄', '☺', '빼', '는', 'Ğ', '🏋', '👨', '🖥', '🌯', 'N', '(', '강', '⛈', '8', '\\x91', '레', '🗡', '🥘', '王', '🐫', '⚜', '･', '🇨', '⏸', '｜', 'и', '🍍', '🆗', '엠', '🕶', '▒', '⚠', '８', '🇩', '赫', '🖤', '♥', '✋', '嫌', '즈', '🎷', 'х', '学', '」', 'ㅋ', '🕜', '년', 'л', '📴', '🐡', '利', 'ø', '🐰', '🏾', '🚬', '¯', '♎', '출', 'w', '🔒', '😴', '🌷', '７', '_', '🎬', '🆔', '위', '펀', '스', '😉', '⋭', '合', '😶', '❗', '🏉', '💅', '界', '🖖', '🌗', 'เ', '⚝', '🎪', '🎭', 'は', '🚁', '】', '규', '📿', '้', '♂', 'ᴗ', '🌠', '🦀', '➎', '❀', '\\u2009', '국', '😣', '압', '🐺', '踊', '⋪', '=', '🅿', 'ヮ', '🎍', '🍊', '☕', '📞', '▙', '내', '🙄', '🙈', 'カ', 'ं', '🛫', '녀', '彡', '🛬', '🏓', '◄', '—', '💽', '🔉', 'ู', '许', '✓', '{', '🇼', '🔌', '☜', 'ｒ', 'x', '📖', '킹', '‘', '팁', '🈶', '👩', '⇨', '✔', '🔞', '🤦', 'コ', '❋', 'ب', 'ы', '태', 'ポ', '🔲', '여', '空', '슨', 'イ', '📺', '<', 'ㅡ', 'Z', '🦄', 'ꠎ', '🕘', '❣', 'k', '🌏', '↘', '애', '⬇', 'ش', 'l', 'ò', '🍓', '🙅', '름', '🍬', '🌬', 'Ｔ', '😤', '✿', '📅', '📂', 't', 'え', '▊', 'っ', '꼼', '🍸', '結', '🕊', 'ロ', '🇦', '📋', '🖐', 'o', '너', 'ェ', 'e', 'ネ', 'Ã', 'œ', '러', '„', 'ⓙ', '기', '⚪', '섹', '☙', '♀', '🏿', '🇴', '⚡', '일', '﹏', '🍃', '∇', 'ح', '쿱', '👇', '엑', '☣', '벳', '톡', '۶', '？', '¨', '📍', '🎨', '🐇', '원', 'ｍ', '🗂', '🏈', '稿', '#', '📝', 'B', '′', '₹', 'क', '🍹', '悪', '젤', 'ラ', 'ú', '６', 'a', '\\x7f', '🌶', '♬', '♓', 'ⁱ', '༼', '🎼', '정', '🦋', '🤕', 'ز', 'ต', '｀', '비', '라', '❤', '↗', '🚢', 'Ｄ', 'y', '💡', '👡', 'ʰ', '🆖', '💄', '😟', '⦑', '╲', '📣', '🤘', '🐳', '💥', '╰', 'ニ', '🐈', 'ᶠ', '🌳', '呟', '知', 'ذ', 'ナ', '🌋', '🔥', 'Ó', '😔', 'а', '€', 'Ｏ', '9', 'Y', '🌮', '듀', '🎙', '🍇', '洲', '🌧', '🤜', 'ｖ', '➢', '왕', '´', '😋', 'Ù', '🌀', 'ト', 'о', '💞', '🌇', 'ⁿ', 'お', '◼', '✈', '🇬', 'È', '後', '양', '채', '🐚', '🤝', '🐉', 'е', '⒑', '😌', 'ʔ', 'ᴰ', '늘', 'Å', 'ｎ', '😑', '⎋', '🔝', '도', '엘', '🕎', '용', '베', '📈', 'ù', '🍗', '👳', '풀', 'ñ', '⏩', '치', '로', 'が', '➞', '💵', 'ï', '♫', 'む', 'Ê', '살', '🍳', '플', '🎹', '°', '블', 'グ', '🐙', '▸', '😥', '👍', '🎮', 'X', '😝', '😛', '\\u200b', '👠', '🇳', '📲', 'ิ', '🐠', '아', 'Q', '£', '🎡', '⑥', 'غ', '리', '💻', '✨', '곡', '🍣', '😇', '➡', '❓', '🙍', '🏽', 'Ｉ', '🇻', '와', 'ा', '추', '😖', '시', '🐶', '무', 'ᵐ', 'ت', '⛓', '셩', 'J', '🥊', '👻', '😍', '🏼', '🏫', 'м', '🚘', '◇', 'Ｗ', 'า', '🤧', '환', '👉', '🎀', '⚘', '🍭', '삼', '⚔', '🐨', '🗓', '☯', '🍟', 'ğ', '👫', '🇪', '디', 'Ｇ', 'ç', 'ã', '바', '👿', '📆', '🌰', '🇸', '「', '😬', '▏', 'O', '🗞', '🥒', 'ด', '🌈', '⛔', '🛄', 'ê', '커', '🍆', '결', 'ｄ', '👟', '［', '🚮', '`', '✝', '🛰', 'Ö', '⦒', '영', 'エ', 'ô', '♤', 'ข', '🏻', '🍉', '本', '💫', '\\u3000', 'Ｙ', '🕟', 'Ÿ', 'ワ', 'ब', '📹', '行', 'у', '🐀', '⚫', '🌵', '@', '밀', '🤐', '😲', 'ล', '➏', 'Ц', '█', 'M', '찌', 'タ', '🏀', 'ョ', '🍕', 'ｓ', '화', '🍂', '＠', '😽', '↑', '룸', '🔰', '🚩', '🏌', '⇘', 'ｏ', '、', '✷', '¥', '링', '♦', '등', 'ン', '👗', '➊', '소', 'Î', '🔫', '🚿', 'แ', 'ッ', '⚽', '彼', '💧', '🆚', 'で', '🚖', 'ض', '📱', '🎊', '←', '우', '😧', '🎂', '🎲', '🇱', '║', '∴', '💓', '복', '🇽', 'を', '🐍', '집', '🍰', '논', 'ⓢ', '╩', '者', '🔺', '（', '柱', '👷', '☘', '😳', '゜', '쥔', '🔊', '틴', '✉', '希', '\\n', '🏁', '．', 'م', '다', '🌤', '🇰', '😙', 'ˢ', 'ส', '😄', '🔄', '╔', '🆕', '月', '힐', '💚', '💋', '근', '워', '🤤', '◀', '🙃', '💐', 'Â', '수', '🔼', 'Ｂ', '↪', '🖕', '๐', '🗼', '💛', '🌐', \"'\", '😗', '〡', '☎', '南', '🇮', '🥇', '‹', '่', '3', '尔', '❔', '🔱', '🏖', '『', '生', '嘉', '🏊', 'ᵇ', '👀', '🍛', '¿', 'f', '맞', '︎', 'p', '⛽', '울', '￣', '🐻', '༽', '❅', 'э', 's', '╮', '성', '▲', '😐', 'ญ', 'フ', '🇹', '⛷', '🗨', '🏘', '用', '⚰', '毅', '😺', '서', '،', '😪', '🐆', '💊', 'И', '🙁', '👽', '努', 'د', '🌛']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2\n",
        "Implement the function *lm* that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant *n*-1 sequences, and the values are dictionaries with the *n*_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
        "\n",
        "{ \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25}, \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1} }\n",
        "\n",
        "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
        "\n",
        "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
      ],
      "metadata": {
        "id": "tpjtwHW08jyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_unigram_model(tweet_texts, smoothed, vocabulary):\n",
        "    model = {'א': len(tweet_texts), 'ת': len(tweet_texts)}\n",
        "    total_characters = sum((len(tweet)+2) for tweet in tweet_texts)\n",
        "\n",
        "    for tweet in tweet_texts:\n",
        "      for char in tweet:\n",
        "        if char in model:\n",
        "            model[char] += 1\n",
        "        else:\n",
        "            model[char] = 1\n",
        "\n",
        "    for char in model:\n",
        "        model[char] = model[char] / total_characters\n",
        "\n",
        "    if smoothed:\n",
        "        model['<unk>'] = 1 / len(vocabulary)\n",
        "    return model\n",
        "\n",
        "def add_n_gram(model, counts, n_gram, suffix):\n",
        "  if n_gram in model.keys():\n",
        "    if suffix in model[n_gram]:\n",
        "      model[n_gram][suffix] += 1\n",
        "    else:\n",
        "      model[n_gram][suffix] = 1\n",
        "    counts[n_gram] += 1\n",
        "  else:\n",
        "    model[n_gram] = {suffix: 1}\n",
        "    counts[n_gram] = 1\n",
        "\n",
        "def lm(lang: str, n: int, smoothed: bool = False) -> dict[str, dict[str, float]]:\n",
        "  '''\n",
        "  Return a language model for the given lang and n_gram (n)\n",
        "  :param lang: the language of the model\n",
        "  :param n: the n_gram value\n",
        "  :return: a dictionary where the keys are n_grams and the values are dictionaries\n",
        "  '''\n",
        "  model = {}\n",
        "  counts = {}\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  file_path = os.path.join('/content/data', f'{lang}.json')\n",
        "  tweet_texts = get_tweet_texts(file_path)\n",
        "\n",
        "  if n == 1:\n",
        "    return create_unigram_model(tweet_texts, smoothed, vocabulary)\n",
        "\n",
        "  for tweet in tweet_texts:\n",
        "    tweet = \"א\" * (n-1) + tweet + \"ת\"\n",
        "    for i in range(len(tweet)-n+1):\n",
        "        n_gram = tweet[i:i+n-1]\n",
        "        suffix = tweet[i+n-1]\n",
        "        add_n_gram(model, counts, n_gram, suffix)\n",
        "\n",
        "  for n_gram, followers in model.items():\n",
        "    for suffix in followers:\n",
        "      if smoothed:\n",
        "        model[n_gram][suffix] = (model[n_gram][suffix] + 1) / (counts[n_gram] + len(vocabulary))\n",
        "      else:\n",
        "        model[n_gram][suffix] = model[n_gram][suffix] / counts[n_gram]\n",
        "\n",
        "  if smoothed:\n",
        "    model['<unk>'] = 1 / len(vocabulary)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "print(lm('en', 1, True))"
      ],
      "metadata": {
        "id": "uySEXdEUrkq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3c7c92-40ab-4333-f0b3-9a781972dad4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'א': 0.010404015869160392, 'ת': 0.010404015869160392, 'R': 0.009852296517343881, 'T': 0.012585447100870954, ' ': 0.13628277640908198, '@': 0.009886995847646808, 'O': 0.00480007402523798, 'N': 0.003984639763119239, 'H': 0.0037683472708976715, 'E': 0.004626577373723354, 'P': 0.0035520547786761047, 'l': 0.027951467203349643, 'D': 0.003939530633725436, ':': 0.012956729935112252, 'B': 0.003858565529685277, 'o': 0.05263078755913344, 'y': 0.015909642943891182, 'f': 0.011044796835421077, 'r': 0.03567438148443735, 'i': 0.04097181257735059, 'e': 0.06718137339949339, 'n': 0.03939761962594122, 'd': 0.019728882565899813, 's': 0.04193876724845877, 't': 0.0636038724452618, 'h': 0.03140173727980383, 'a': 0.04990342019732352, 'k': 0.008338249071792914, 'p': 0.01844385070034815, 'c': 0.022158992331448003, 'u': 0.01918988630186104, 'g': 0.013568594792787166, 'w': 0.011410296447945221, 'm': 0.016614039349040564, '😁': 2.3132886868616768e-05, '☺': 1.619302080803174e-05, '️': 0.0003666562568675758, 'b': 0.009802560810576356, \"'\": 0.00344911343211076, '/': 0.018500526273176263, '.': 0.013265553974808286, '5': 0.0018309679956510173, 'M': 0.004949281145540558, 'A': 0.005866500109881213, '8': 0.0013486473044403576, '1': 0.002893924147263958, 'F': 0.0033519553072625698, 'v': 0.007238280301190187, '_': 0.001576506240096233, '9': 0.001481661403934904, '2': 0.0024312664098916224, 'I': 0.006385833420081659, 'C': 0.004885665706651862, 'U': 0.0022809026452456135, 'Y': 0.002500665070497473, '#': 0.004132690239078386, '0': 0.002541147622517552, '7': 0.0016077356373688655, 'L': 0.004078327954937136, 'V': 0.0017777623558531987, 'S': 0.0070751934487664385, 'X': 0.001201753472824641, '6': 0.0014770348265611807, 'K': 0.002277432712215321, ',': 0.002651028835143482, 'G': 0.003229351006858901, 'W': 0.0036700325017060506, '3': 0.001768509201105752, '&': 0.0005308997536347548, '!': 0.0024231698994876066, 'Q': 0.0011485478330268226, 'J': 0.0020553569982765998, '’': 0.00021166591484784344, '-': 0.0012179464936326728, 'Z': 0.0011231016574713441, 'z': 0.0020646101530240467, '$': 0.0001052546352522063, '😥': 2.313288686861677e-06, '👀': 2.8916108585770962e-05, '🙏': 3.816926333321767e-05, 'q': 0.0012942850202991082, '4': 0.0017766057115097679, '~': 3.122939727263264e-05, 'j': 0.0023352649293868627, '🍀': 2.313288686861677e-06, '👊': 8.09651040401587e-06, 'x': 0.0024983517818106113, '\"': 0.0012422360248447205, '🤦': 2.3132886868616768e-05, '🏽': 6.939866060585031e-05, '\\u200d': 4.973570676752605e-05, '♂': 1.50363764646009e-05, '😂': 0.00040713880888765513, '…': 0.0019882716263576114, '(': 0.0003469933030292515, ')': 0.0003759094116150225, '🌹': 9.253154747446708e-06, '?': 0.0011265715905016366, '💥': 1.9662953838324255e-05, '💯': 3.122939727263264e-05, '✔': 1.619302080803174e-05, '>': 0.00010178470222191378, '⭐': 4.626577373723354e-06, '➡': 1.619302080803174e-05, '⬅': 2.313288686861677e-06, '[': 8.096510404015869e-05, ']': 7.749517100986618e-05, '‼': 9.253154747446708e-06, '＠': 9.253154747446708e-06, '😘': 2.197624252518593e-05, '*': 0.00020588269313068924, '🙀': 1.1566443434308385e-06, '%': 0.00010872456828249882, '👍': 2.6602819898909284e-05, '🤗': 1.50363764646009e-05, '😛': 8.09651040401587e-06, '🙌': 3.932590767664851e-05, '😎': 3.00727529292018e-05, '😆': 1.0409799090877545e-05, '🏻': 5.089235111095689e-05, '✨': 6.824201626241947e-05, '♥': 1.7349665151462578e-05, '♡': 5.783221717154192e-06, '“': 0.00010641127959563714, '😍': 0.00016771342979747156, '🤣': 3.00727529292018e-05, '😤': 1.3879732121170062e-05, '🏼': 6.130215020183444e-05, '•': 2.4289531212047607e-05, '📲': 5.783221717154192e-06, '👉': 1.8506309494893417e-05, '🎤': 1.3879732121170062e-05, '🎧': 1.3879732121170062e-05, '🇳': 9.253154747446708e-06, '🇬': 9.253154747446708e-06, '👇': 4.626577373723354e-06, 'ㅤ': 0.0002313288686861677, '🌴': 1.1566443434308384e-05, '🖤': 5.783221717154192e-06, '🤳': 1.1566443434308385e-06, '🌊': 3.4699330302925154e-06, '☀': 1.0409799090877545e-05, '”': 9.253154747446707e-05, '❤': 0.000150363764646009, '+': 8.096510404015869e-05, '😄': 9.253154747446708e-06, '↘': 1.1566443434308385e-06, '↗': 1.1566443434308385e-06, '🐘': 2.313288686861677e-06, '📦': 1.1566443434308385e-06, '|': 0.00010409799090877546, '🇱': 4.626577373723354e-06, '🎼': 6.939866060585031e-06, '🎶': 2.6602819898909284e-05, '💐': 5.783221717154192e-06, '👈': 8.09651040401587e-06, '💅': 2.313288686861677e-06, '⠀': 2.313288686861677e-06, '🔥': 0.00010988121262592965, '😫': 8.09651040401587e-06, '😏': 2.081959818175509e-05, '💿': 3.4699330302925154e-06, ';': 8.559168141388204e-05, '💙': 3.354268595949432e-05, '—': 4.163919636351018e-05, '℃': 1.1566443434308385e-06, '⇘': 1.1566443434308385e-06, '´': 4.626577373723354e-06, '^': 1.8506309494893417e-05, '⚽': 1.0409799090877545e-05, '🇿': 1.1566443434308385e-06, '🎓': 1.0409799090877545e-05, 'é': 1.2723087777739223e-05, 'А': 1.1566443434308385e-06, 'р': 2.313288686861677e-06, 'х': 1.1566443434308385e-06, 'и': 1.1566443434308385e-06, 'т': 2.313288686861677e-06, 'е': 1.1566443434308385e-06, 'к': 1.1566443434308385e-06, 'у': 1.1566443434308385e-06, 'а': 1.1566443434308385e-06, '😭': 0.00015730363070659404, '💪': 3.816926333321767e-05, '🦁': 3.4699330302925154e-06, '🎙': 2.313288686861677e-06, '￼': 2.313288686861677e-06, '🇮': 1.1566443434308384e-05, '🇹': 6.939866060585031e-06, '🇦': 3.4699330302925154e-06, '£': 2.5446175555478446e-05, '🙁': 5.783221717154192e-06, '\\u200b': 5.783221717154192e-06, '🍴': 2.313288686861677e-06, '😴': 1.3879732121170062e-05, '🆓': 6.939866060585031e-06, '❓': 4.626577373723354e-06, '🍱': 6.939866060585031e-06, '🍣': 6.939866060585031e-06, '👶': 9.253154747446708e-06, '🐾': 1.2723087777739223e-05, '🙈': 9.253154747446708e-06, '🐷': 9.253154747446708e-06, '🐣': 8.09651040401587e-06, '🐔': 6.939866060585031e-06, '👹': 6.939866060585031e-06, '👿': 8.09651040401587e-06, '🔫': 8.09651040401587e-06, '💣': 8.09651040401587e-06, '☠': 9.253154747446708e-06, '😷': 1.50363764646009e-05, '🔪': 2.3132886868616768e-05, '💚': 5.783221717154192e-06, '🔁': 2.313288686861677e-06, '🤘': 8.09651040401587e-06, '🌚': 4.626577373723354e-06, '�': 4.626577373723354e-06, '💃': 5.783221717154192e-06, '–': 2.081959818175509e-05, '🇺': 9.253154747446708e-06, '🇸': 9.253154747446708e-06, '😌': 1.0409799090877545e-05, 'Ω': 1.1566443434308385e-06, '🐺': 8.09651040401587e-06, '💫': 1.1566443434308384e-05, '👑': 9.253154747446708e-06, '\\\\': 3.4699330302925154e-06, 'ㅠ': 4.626577373723354e-06, '👏': 4.8579062424095214e-05, '🐞': 1.1566443434308385e-06, '🎉': 1.619302080803174e-05, '{': 3.4699330302925154e-06, '}': 3.4699330302925154e-06, '📞': 1.1566443434308385e-06, '🌺': 3.4699330302925154e-06, '🌸': 1.3879732121170062e-05, '™': 1.3879732121170062e-05, 'Ｒ': 5.783221717154192e-06, 'Ｅ': 1.0409799090877545e-05, 'Ｔ': 6.939866060585031e-06, 'Ｗ': 1.2723087777739223e-05, 'Ｏ': 1.50363764646009e-05, 'Ｎ': 6.939866060585031e-06, 'Ｌ': 1.2723087777739223e-05, 'Ｙ': 3.4699330302925154e-06, 'Ｉ': 4.626577373723354e-06, 'Ｆ': 8.09651040401587e-06, 'Ｕ': 2.313288686861677e-06, '〡': 1.7349665151462578e-05, 'Ｂ': 2.313288686861677e-06, 'Ａ': 5.783221717154192e-06, 'Ｃ': 2.313288686861677e-06, 'Ｋ': 2.313288686861677e-06, '🏌': 2.313288686861677e-06, '🌎': 3.4699330302925154e-06, '💓': 1.50363764646009e-05, '✌': 1.619302080803174e-05, '🗽': 1.1566443434308385e-06, 'ø': 1.1566443434308385e-06, '😩': 3.122939727263264e-05, '😐': 9.253154747446708e-06, '💀': 2.8916108585770962e-05, '☹': 5.783221717154192e-06, '↺': 9.253154747446708e-06, '😻': 3.4699330302925154e-06, '💖': 1.8506309494893417e-05, '💕': 3.122939727263264e-05, '👰': 3.4699330302925154e-06, '🏾': 5.5518928484680246e-05, '¿': 5.783221717154192e-06, '⃣': 1.3879732121170062e-05, '🤔': 3.4699330302925156e-05, '🍃': 5.783221717154192e-06, '👌': 2.4289531212047607e-05, '‘': 2.8916108585770962e-05, '😅': 9.253154747446708e-06, '😇': 1.3879732121170062e-05, '👠': 3.4699330302925154e-06, '😊': 2.5446175555478446e-05, '💋': 1.2723087777739223e-05, '🙋': 1.1566443434308385e-06, '😚': 1.1566443434308385e-06, '🍊': 2.313288686861677e-06, '®': 1.1566443434308385e-06, '🤷': 2.5446175555478446e-05, '=': 2.6602819898909284e-05, '✉': 2.313288686861677e-06, '🎟': 2.313288686861677e-06, '💗': 1.2723087777739223e-05, '❄': 6.939866060585031e-06, '👨': 2.313288686861677e-06, '⚕': 1.1566443434308385e-06, '🐝': 6.939866060585031e-06, '<': 2.7759464242340123e-05, '🤤': 3.4699330302925154e-06, '🙄': 2.5446175555478446e-05, '🤓': 4.626577373723354e-06, '🦄': 3.4699330302925154e-06, '🌈': 5.783221717154192e-06, '→': 1.1566443434308385e-06, '🇪': 6.939866060585031e-06, '🇲': 1.1566443434308385e-06, '🇩': 2.313288686861677e-06, '🔴': 8.09651040401587e-06, '🍑': 4.626577373723354e-06, '🥇': 2.313288686861677e-06, '🏆': 3.4699330302925154e-06, '♀': 3.5855974646355994e-05, '😕': 3.4699330302925154e-06, '😬': 3.4699330302925154e-06, '😀': 8.09651040401587e-06, '⛪': 1.1566443434308385e-06, '🚘': 2.313288686861677e-06, '😖': 2.313288686861677e-06, '🌐': 2.313288686861677e-06, '😮': 3.4699330302925154e-06, '😑': 6.939866060585031e-06, '🙃': 1.0409799090877545e-05, '⁉': 2.313288686861677e-06, '😱': 1.3879732121170062e-05, '😔': 1.2723087777739223e-05, '،': 1.1566443434308385e-06, '📢': 3.4699330302925154e-06, '🚨': 1.9662953838324255e-05, 'ᴰ': 3.4699330302925154e-06, 'ᵃ': 1.619302080803174e-05, 'ᵇ': 4.626577373723354e-06, 'ᵗ': 4.626577373723354e-06, 'ʸ': 4.626577373723354e-06, 'ᵒ': 3.4699330302925154e-06, 'ᵘ': 2.313288686861677e-06, 'ʳ': 6.939866060585031e-06, 'ˢ': 2.313288686861677e-06, 'ᵉ': 5.783221717154192e-06, 'ᵛ': 1.1566443434308385e-06, 'ⁱ': 2.313288686861677e-06, 'ᶜ': 1.1566443434308385e-06, 'ˡ': 1.1566443434308385e-06, 'ʷ': 2.313288686861677e-06, 'ᵈ': 3.4699330302925154e-06, 'ᶠ': 2.313288686861677e-06, 'ʰ': 3.4699330302925154e-06, '⁷': 1.1566443434308385e-06, '🤢': 2.313288686861677e-06, '🚖': 1.1566443434308385e-06, '📷': 1.0409799090877545e-05, '☛': 1.1566443434308385e-06, '☚': 1.1566443434308385e-06, '💔': 1.0409799090877545e-05, '🏀': 3.4699330302925154e-06, '♣': 4.626577373723354e-06, '🔱': 4.626577373723354e-06, 'ⓦ': 2.313288686861677e-06, 'ⓘ': 2.313288686861677e-06, 'ⓢ': 4.626577373723354e-06, '😰': 1.1566443434308385e-06, '🖕': 0.00010988121262592965, '「': 1.1566443434308385e-06, '」': 1.1566443434308385e-06, '젤': 2.313288686861677e-06, '로': 2.313288686861677e-06, '🌞': 5.783221717154192e-06, '👙': 1.1566443434308385e-06, '»': 8.09651040401587e-06, '«': 1.1566443434308385e-06, '🔜': 2.313288686861677e-06, 'ح': 2.313288686861677e-06, 'ي': 3.4699330302925154e-06, 'ا': 8.09651040401587e-06, 'ت': 2.313288686861677e-06, 'ك': 2.313288686861677e-06, 'ل': 3.4699330302925154e-06, 'و': 3.4699330302925154e-06, 'ه': 2.313288686861677e-06, 'م': 5.783221717154192e-06, 'ن': 1.1566443434308385e-06, 'غ': 1.1566443434308385e-06, 'ر': 8.09651040401587e-06, '🙆': 1.1566443434308385e-06, '🌧': 2.313288686861677e-06, '😒': 9.253154747446708e-06, '🙂': 6.939866060585031e-06, '❝': 4.626577373723354e-06, '❞': 4.626577373723354e-06, '💰': 5.783221717154192e-06, '🎾': 1.1566443434308385e-06, '✊': 9.253154747446708e-06, '🏿': 2.313288686861677e-06, '🐙': 2.313288686861677e-06, '🗣': 1.3879732121170062e-05, '💜': 1.2723087777739223e-05, '🌅': 1.1566443434308385e-06, '🏖': 1.1566443434308385e-06, '🐚': 1.1566443434308385e-06, '🏄': 1.1566443434308385e-06, '\\U000fe4e6': 3.4699330302925154e-06, '➤': 2.313288686861677e-06, '\\x91': 1.1566443434308385e-06, '\\x92': 2.313288686861677e-06, '🎈': 2.313288686861677e-06, '🤙': 2.313288686861677e-06, '😋': 8.09651040401587e-06, '틴': 3.4699330302925154e-06, '탑': 2.313288686861677e-06, '하': 2.313288686861677e-06, '이': 4.626577373723354e-06, '파': 2.313288686861677e-06, '브': 2.313288686861677e-06, '리': 3.4699330302925154e-06, '키': 2.313288686861677e-06, '😉': 1.2723087777739223e-05, '😪': 8.09651040401587e-06, 'ط': 4.626577373723354e-06, 'د': 2.313288686861677e-06, 'ج': 1.1566443434308385e-06, 'ع': 1.1566443434308385e-06, 'ق': 1.1566443434308385e-06, '🎊': 9.253154747446708e-06, '🥂': 5.783221717154192e-06, '💛': 5.783221717154192e-06, '⚫': 1.1566443434308385e-06, '🔵': 2.313288686861677e-06, '😨': 2.313288686861677e-06, '😜': 9.253154747446708e-06, '😢': 4.626577373723354e-06, '🏈': 1.1566443434308385e-06, '〰': 3.4699330302925154e-06, '⬇': 2.313288686861677e-06, '😡': 4.626577373723354e-06, '⦑': 1.1566443434308385e-06, '⦒': 1.1566443434308385e-06, '⎋': 1.1566443434308385e-06, '⸄': 1.1566443434308385e-06, '⸅': 1.1566443434308385e-06, '💨': 4.626577373723354e-06, '👅': 5.783221717154192e-06, '🐍': 2.313288686861677e-06, '🐡': 1.1566443434308385e-06, '🦀': 2.313288686861677e-06, '🦑': 2.313288686861677e-06, '😣': 1.1566443434308385e-06, '🍻': 4.626577373723354e-06, '➙': 1.1566443434308385e-06, '午': 1.1566443434308385e-06, '後': 1.1566443434308385e-06, '８': 1.1566443434308385e-06, '時': 1.1566443434308385e-06, '３': 1.1566443434308385e-06, '分': 1.1566443434308385e-06, '진': 2.313288686861677e-06, '석': 1.1566443434308385e-06, '찌': 1.1566443434308385e-06, '니': 1.1566443434308385e-06, '방': 5.783221717154192e-06, '탄': 5.783221717154192e-06, '소': 4.626577373723354e-06, '년': 4.626577373723354e-06, '단': 4.626577373723354e-06, '☁': 1.1566443434308385e-06, '🌷': 5.783221717154192e-06, '💞': 1.0409799090877545e-05, '😈': 1.8506309494893417e-05, '©': 4.626577373723354e-06, '🍿': 1.1566443434308385e-06, '🎁': 4.626577373723354e-06, '👲': 1.1566443434308385e-06, '💟': 3.4699330302925154e-06, '👓': 1.1566443434308385e-06, '🌟': 1.0409799090877545e-05, '🌙': 3.4699330302925154e-06, '📰': 2.313288686861677e-06, '💄': 1.1566443434308385e-06, '🌥': 1.1566443434308385e-06, '📸': 1.1566443434308385e-06, '⚡': 4.8579062424095214e-05, '➊': 4.626577373723354e-06, '➋': 4.626577373723354e-06, '➌': 4.626577373723354e-06, '➍': 4.626577373723354e-06, '➎': 3.4699330302925154e-06, '➏': 3.4699330302925154e-06, '☞': 4.626577373723354e-06, '🤑': 2.313288686861677e-06, '💵': 4.626577373723354e-06, '💸': 4.626577373723354e-06, '―': 4.626577373723354e-06, '\\n': 2.313288686861677e-06, 'ō': 1.1566443434308385e-06, '🐲': 1.1566443434308385e-06, '🦉': 1.1566443434308385e-06, '🤕': 1.1566443434308385e-06, '🤒': 1.1566443434308385e-06, '😓': 3.4699330302925154e-06, '🎨': 2.313288686861677e-06, '🍕': 1.1566443434308385e-06, '🌻': 2.313288686861677e-06, '🅱': 1.1566443434308385e-06, '🐊': 1.1566443434308385e-06, '☘': 5.783221717154192e-06, '😞': 4.626577373723354e-06, '정': 3.4699330302925154e-06, '국': 1.1566443434308385e-06, '☄': 1.1566443434308385e-06, '🌋': 1.1566443434308385e-06, '❣': 5.783221717154192e-06, '🐶': 4.626577373723354e-06, '지': 2.313288686861677e-06, '민': 1.1566443434308385e-06, '🐯': 1.1566443434308385e-06, '🐄': 1.1566443434308385e-06, '🐖': 1.1566443434308385e-06, '🐓': 1.1566443434308385e-06, '🍆': 2.313288686861677e-06, '💦': 8.09651040401587e-06, '👄': 2.313288686861677e-06, '🔞': 2.313288686861677e-06, '📹': 1.1566443434308385e-06, 'ç': 1.1566443434308385e-06, '∆': 1.1566443434308385e-06, '💆': 2.313288686861677e-06, '🗳': 1.1566443434308385e-06, '🍽': 1.1566443434308385e-06, '・': 6.939866060585031e-06, '😝': 3.4699330302925154e-06, '⛳': 1.1566443434308385e-06, '❗': 1.7349665151462578e-05, '💎': 3.4699330302925154e-06, '🐻': 1.1566443434308385e-06, '🐼': 1.1566443434308385e-06, '👁': 2.313288686861677e-06, '프': 1.1566443434308385e-06, '스': 5.783221717154192e-06, '💍': 3.4699330302925154e-06, '🐩': 1.1566443434308385e-06, '💁': 9.253154747446708e-06, '유': 1.1566443434308385e-06, '연': 2.313288686861677e-06, '😽': 5.783221717154192e-06, '아': 3.4699330302925154e-06, '름': 3.4699330302925154e-06, '다': 3.4699330302925154e-06, '워': 3.4699330302925154e-06, '🍾': 2.313288686861677e-06, '¡': 6.939866060585031e-06, '🎋': 1.1566443434308385e-06, '💈': 2.313288686861677e-06, '⚠': 1.619302080803174e-05, '🌾': 3.4699330302925154e-06, '🌼': 3.4699330302925154e-06, '👆': 1.1566443434308385e-06, '세': 1.1566443434308385e-06, '훈': 1.1566443434308385e-06, '🏊': 1.1566443434308385e-06, '😳': 1.3879732121170062e-05, 'Ｇ': 3.4699330302925154e-06, '🐐': 3.4699330302925154e-06, '🇧': 3.4699330302925154e-06, '¯': 4.626577373723354e-06, 'ツ': 2.313288686861677e-06, '🇵': 2.313288686861677e-06, '😯': 1.1566443434308385e-06, '🍺': 2.313288686861677e-06, '🍋': 1.1566443434308385e-06, '🍇': 4.626577373723354e-06, 'ï': 2.313288686861677e-06, '🙇': 2.313288686861677e-06, '🌳': 1.1566443434308385e-06, '↪': 1.1566443434308385e-06, '🙅': 3.4699330302925154e-06, '👐': 2.313288686861677e-06, '🥘': 1.1566443434308385e-06, '🎮': 1.1566443434308385e-06, '✈': 1.1566443434308385e-06, '🔹': 1.1566443434308385e-06, '💽': 1.1566443434308385e-06, '͡': 2.313288686861677e-06, '°': 1.2723087777739223e-05, '͜': 1.1566443434308385e-06, 'ʖ': 1.1566443434308385e-06, '🍼': 1.1566443434308385e-06, '레': 1.1566443434308385e-06, '드': 1.1566443434308385e-06, '벨': 1.1566443434308385e-06, '벳': 1.1566443434308385e-06, '✅': 5.783221717154192e-06, '📚': 3.4699330302925154e-06, '✧': 1.1566443434308385e-06, '☕': 1.1566443434308385e-06, '🆘': 2.313288686861677e-06, '🔶': 2.313288686861677e-06, '⏩': 1.1566443434308385e-06, '🌰': 1.1566443434308385e-06, '👻': 2.313288686861677e-06, '🤧': 2.313288686861677e-06, 'á': 1.1566443434308385e-06, '💌': 1.1566443434308385e-06, '👋': 4.626577373723354e-06, '🇴': 1.1566443434308385e-06, 'ü': 3.4699330302925154e-06, '❌': 4.626577373723354e-06, '📺': 3.4699330302925154e-06, '`': 2.313288686861677e-06, '🤚': 1.1566443434308385e-06, '👤': 1.1566443434308385e-06, '카': 1.1566443434308385e-06, '노': 1.1566443434308385e-06, '게': 1.1566443434308385e-06, '임': 1.1566443434308385e-06, '\\u3000': 2.313288686861677e-06, '♯': 1.1566443434308385e-06, '🍯': 1.1566443434308385e-06, 'Ö': 1.1566443434308385e-06, '┏': 3.4699330302925154e-06, '┓': 3.4699330302925154e-06, '┃': 3.4699330302925154e-06, '╱': 8.09651040401587e-06, '╲': 6.939866060585031e-06, '╭': 2.313288686861677e-06, '╮': 2.313288686861677e-06, '▔': 1.3879732121170062e-05, '▏': 1.1566443434308385e-06, '┗': 1.1566443434308385e-06, '┛': 1.1566443434308385e-06, '▕': 1.1566443434308385e-06, '┳': 2.313288686861677e-06, '🤞': 1.1566443434308385e-06, '💝': 2.313288686861677e-06, '📈': 1.1566443434308385e-06, '🎗': 2.313288686861677e-06, '☑': 1.1566443434308385e-06, '👯': 1.1566443434308385e-06, '🇰': 1.1566443434308385e-06, '📅': 1.1566443434308385e-06, '🏃': 1.1566443434308385e-06, '🍳': 1.1566443434308385e-06, '⚔': 1.1566443434308385e-06, '⚪': 3.4699330302925154e-06, '》': 4.626577373723354e-06, 'í': 1.1566443434308385e-06, '🐑': 1.1566443434308385e-06, '💉': 3.4699330302925154e-06, '🍔': 3.4699330302925154e-06, '😃': 4.626577373723354e-06, '🚣': 1.1566443434308385e-06, 'ë': 1.1566443434308385e-06, '🎂': 1.1566443434308385e-06, '👭': 1.1566443434308385e-06, '➜': 1.1566443434308385e-06, '💭': 1.1566443434308385e-06, '듀': 1.1566443434308385e-06, '엣': 1.1566443434308385e-06, '가': 1.1566443434308385e-06, '요': 1.1566443434308385e-06, '제': 1.1566443434308385e-06, '👦': 1.1566443434308385e-06, '👧': 1.1566443434308385e-06, '💑': 1.1566443434308385e-06, '👪': 2.313288686861677e-06, '👫': 2.313288686861677e-06, '🎡': 1.1566443434308385e-06, '🎠': 1.1566443434308385e-06, '🎢': 1.1566443434308385e-06, '🎪': 1.1566443434308385e-06, '⛓': 2.313288686861677e-06, '몬': 2.313288686861677e-06, '타': 2.313288686861677e-06, '엑': 2.313288686861677e-06, '셔': 1.1566443434308385e-06, '누': 1.1566443434308385e-06, 'ᴬ': 1.1566443434308385e-06, 'ᶰ': 2.313288686861677e-06, '♎': 1.1566443434308385e-06, '⚝': 6.939866060585031e-06, '🔅': 4.626577373723354e-06, '☙': 5.783221717154192e-06, '☰': 3.4699330302925154e-06, '🔝': 1.1566443434308385e-06, '║': 4.6265773737233536e-05, '⌚': 1.1566443434308385e-06, '✡': 1.1566443434308385e-06, '🕎': 1.1566443434308385e-06, '🇨': 1.1566443434308385e-06, '🔩': 1.1566443434308385e-06, '€': 1.1566443434308385e-06, '💘': 1.1566443434308385e-06, '주': 1.1566443434308385e-06, '헌': 1.1566443434308385e-06, '✋': 1.1566443434308385e-06, '😲': 1.1566443434308385e-06, '호': 1.1566443434308385e-06, '야': 1.1566443434308385e-06, '🍒': 2.313288686861677e-06, '►': 1.1566443434308385e-06, '🎲': 1.1566443434308385e-06, '🍫': 8.09651040401587e-06, '🥔': 1.1566443434308385e-06, '☉': 1.1566443434308385e-06, '☝': 1.1566443434308385e-06, '★': 2.313288686861677e-06, '♛': 1.1566443434308385e-06, '🌌': 1.1566443434308385e-06, '🎒': 1.1566443434308385e-06, '\\x80': 2.313288686861677e-06, '➗': 1.1566443434308385e-06, '🐈': 1.1566443434308385e-06, '🙉': 5.783221717154192e-06, '🐨': 1.1566443434308385e-06, '🙊': 1.1566443434308385e-06, 'ү': 1.1566443434308385e-06, 'Ｄ': 1.1566443434308385e-06, '༺': 2.313288686861677e-06, '☾': 2.313288686861677e-06, '✭': 2.313288686861677e-06, '☽': 2.313288686861677e-06, '༻': 2.313288686861677e-06, 'Ｍ': 1.1566443434308385e-06, 'Ｖ': 1.1566443434308385e-06, '💧': 1.1566443434308385e-06, '🤐': 1.1566443434308385e-06, '😠': 5.783221717154192e-06, '🔐': 1.1566443434308385e-06, '🎹': 1.1566443434308385e-06, '🇷': 1.1566443434308385e-06, '☮': 1.1566443434308385e-06, '✝': 1.1566443434308385e-06, '🏉': 1.1566443434308385e-06, '█': 1.619302080803174e-05, '╚': 1.1566443434308385e-06, '╩': 1.7349665151462578e-05, '╝': 1.1566443434308385e-06, '♬': 1.1566443434308385e-06, '☼': 2.313288686861677e-06, '오': 1.1566443434308385e-06, '늘': 1.1566443434308385e-06, '의': 1.1566443434308385e-06, '🔌': 1.1566443434308385e-06, '🏒': 1.1566443434308385e-06, '🍁': 1.1566443434308385e-06, '♫': 2.313288686861677e-06, '🐱': 1.1566443434308385e-06, '【': 1.1566443434308385e-06, '】': 1.1566443434308385e-06, '🍸': 2.313288686861677e-06, '🍹': 1.1566443434308385e-06, '⚜': 1.1566443434308385e-06, '🕊': 5.783221717154192e-06, '🛴': 1.1566443434308385e-06, '💩': 1.1566443434308385e-06, '<unk>': 0.0005543237250554324}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3\n",
        "Implement the function *eval* that returns the perplexity of a model (dictionary) running over the data file of the given target language."
      ],
      "metadata": {
        "id": "xwZnk7Ke8rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calc_prob(model, n_gram, suffix, vocabulary_size, n):\n",
        "  if n == 1:\n",
        "    if n_gram not in model:\n",
        "      if '<unk>' in model: # smoothed\n",
        "        prob = model['<unk>']\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      prob = model[n_gram]\n",
        "\n",
        "  elif n_gram in model.keys() and suffix in model[n_gram]:\n",
        "    prob = model[n_gram][suffix]\n",
        "  elif '<unk>' in model: # smoothed\n",
        "    prob = model['<unk>']\n",
        "  else:\n",
        "    return 0 # not smoothed\n",
        "\n",
        "  return math.log(prob, 2)\n",
        "\n",
        "def eval(model: dict, target_lang: str, n: int) -> float:\n",
        "  '''\n",
        "  Return the perplexity value calculated over applying the model on the text file\n",
        "  of the target_lang language.\n",
        "  :param model: the language model\n",
        "  :param target_lang: the target language\n",
        "  :return: the perplexity value\n",
        "  '''\n",
        "  perplexities = []\n",
        "  vocabulary_lang = set()\n",
        "  file_path = os.path.join('/content/data', f'{target_lang}.json')\n",
        "  tweet_texts = get_tweet_texts(file_path)\n",
        "  for tweet in tweet_texts:\n",
        "    vocabulary_lang.update(tweet)\n",
        "  vocabulary_lang = list(vocabulary_lang)\n",
        "  vocabulary_size = len(vocabulary_lang)\n",
        "\n",
        "  for tweet in tweet_texts:\n",
        "    total_log_prob = 0\n",
        "    tweet = \"א\" * (n-1) + tweet + \"ת\"\n",
        "    N = len(tweet) - n\n",
        "\n",
        "    for i in range(N-1):\n",
        "      if n == 1:\n",
        "        n_gram = tweet[i]\n",
        "      else:\n",
        "        n_gram = tweet[i:i+n-1]\n",
        "      suffix = tweet[i+n-1]\n",
        "      total_log_prob += calc_prob(model, n_gram, suffix, vocabulary_size, n)\n",
        "\n",
        "    perplexities.append(2 ** (-total_log_prob / N))\n",
        "\n",
        "  return sum(perplexities) / len(perplexities)\n",
        "\n",
        "# round(eval(lm('en', 1, True), 'en', 1))"
      ],
      "metadata": {
        "id": "ef-EglxXrmk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a8f7cd-ff43-4994-c117-fbc969730632"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4\n",
        "Implement the *match* function that calls *eval* using a specific value of *n* for every possible language pair among the languages we have data for. You should call *eval* for every language pair four times, with each call assign a different value for *n* (1-4). Each language pair is composed of the source language and the target language. Before you make the call, you need to call the *lm* function to create the language model for the source language. Then you can call *eval* with the language model and the target language. The function should return a pandas DataFrame with the following four columns: *source_lang*, *target_lang*, *n*, *perplexity*. The values for the first two columns are the two-letter language codes. The value for *n* is the *n* you use for generating the specific perplexity values which you should store in the forth column."
      ],
      "metadata": {
        "id": "9ZYVc7hB84LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match() -> pd.DataFrame:\n",
        "  '''\n",
        "  Return a DataFrame containing one line per every language pair and n_gram.\n",
        "  Each line will contain the perplexity calculated when applying the language model\n",
        "  of the source language on the text of the target language.\n",
        "  :return: a DataFrame containing the perplexity values\n",
        "  '''\n",
        "  results = []\n",
        "  files_list = list(filter(lambda f: f.endswith('.json'), os.listdir('/content/data')))\n",
        "  lang_list = list(map(lambda f: f[:-5], files_list))\n",
        "\n",
        "  for source in lang_list:\n",
        "    for n in range(1,5):\n",
        "      model = lm(source, n, True)\n",
        "\n",
        "\n",
        "      for target in lang_list:\n",
        "          perplexity = eval(model, target, n)\n",
        "          results.append({\n",
        "              'source': source,\n",
        "              'target': target,\n",
        "              'n': n,\n",
        "              'perplexity': perplexity\n",
        "          })\n",
        "\n",
        "  return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "match()"
      ],
      "metadata": {
        "id": "16ew9aZWroPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7b6fe523-ec66-4175-9b12-02e068b721f5"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-62415dd01f53>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-143-62415dd01f53>\u001b[0m in \u001b[0;36mmatch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlang_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           results.append({\n\u001b[1;32m     20\u001b[0m               \u001b[0;34m'source'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-95ab874adc28>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, target_lang, n)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mn_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mtotal_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mperplexities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_log_prob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-95ab874adc28>\u001b[0m in \u001b[0;36mcalc_prob\u001b[0;34m(model, n_gram, suffix, vocabulary_size, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# not smoothed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5\n",
        "Implement the *generate* function which takes a language code, *n*, the prompt (the starting text), the number of tokens to generate, and *r*, which is the random seed for any randomized action you plan to take in your implementation. The function should start generating tokens, one by one, using the language model of the given source language and *n*. The prompt should be used as a starting point for aligning on the probabilities to be used for generating the next token.\n",
        "\n",
        "Note - The generation of the next token should be from the LM's distribution."
      ],
      "metadata": {
        "id": "pAQoR0dH9C3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def sample_from_dist(tokens, probs):\n",
        "    # Calculate the cumulative probability\n",
        "    cum_prob = 0\n",
        "    cum_probabilities = []\n",
        "    for p in probs:\n",
        "        cum_prob += p\n",
        "        cum_probabilities.append(cum_prob)\n",
        "\n",
        "    # Draw a random number in [0, max(cum_probabilities)]\n",
        "    r = random.uniform(0, max(cum_probabilities))\n",
        "\n",
        "    # Find where the random number fits in the cumulative distribution\n",
        "    for i, cp in enumerate(cum_probabilities):\n",
        "        if r < cp:\n",
        "            chosen_char = tokens[i]\n",
        "            break\n",
        "\n",
        "    return chosen_char\n",
        "\n",
        "def generate(lang: str, n: int, prompt: str, number_of_tokens: int, r: int) -> str:\n",
        "  '''\n",
        "  Generate text in the given language using the given parameters.\n",
        "  :param lang: the language of the model\n",
        "  :param n: the n_gram value\n",
        "  :param prompt: the prompt to start the generation\n",
        "  :param number_of_tokens: the number of tokens to generate\n",
        "  :param r: the random seed to use\n",
        "  '''\n",
        "  text = prompt\n",
        "  model = lm(lang, n, True)\n",
        "  n_gram = prompt[-n+1:]\n",
        "\n",
        "  for _ in range(number_of_tokens):\n",
        "    if n == 1 :\n",
        "      distribution = model\n",
        "    else:\n",
        "      distribution = model[n_gram]\n",
        "    tokens = list(distribution.keys())\n",
        "    probs = list(distribution.values())\n",
        "    gen_char = sample_from_dist(tokens, probs)\n",
        "    text += gen_char\n",
        "\n",
        "    if text.endswith('ת'):\n",
        "      break\n",
        "    n_gram = n_gram[1:]\n",
        "    n_gram += gen_char\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "generate('en', 4, \"I eat\", 20, 5)"
      ],
      "metadata": {
        "id": "CpCm24-RrpuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61e2908e-0a53-490f-f613-5261664aef82"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I eatnight bilizayn: thro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6\n",
        "Play with your generate function, try to generate different texts in different language and various values of *n*. No need to submit anything of that."
      ],
      "metadata": {
        "id": "eUWX8Ugu9INH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ykbMBzG9LWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZTlc2ieruqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c67dda54-0276-4705-8184-a6f0a50ae206"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02563371-b31b-40c3-bf71-ed58952d12f7\", \"results.json\", 912)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "q2jNlDISr9aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the content of the **tests.py** file from the repo and paste below. This will create the results.json file and download it to your machine."
      ],
      "metadata": {
        "id": "uv48OCT_sIYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the local files, results.json should be there now and\n",
        "# also downloaded to your local machine\n",
        "####################\n",
        "# PLACE TESTS HERE #\n",
        "\n",
        "####################\n",
        "# Create tests\n",
        "\n",
        "\n",
        "# Create tests\n",
        "def test_preprocess():\n",
        "    return {\n",
        "        'vocab_length': len(preprocess()),\n",
        "    }\n",
        "\n",
        "def test_lm():\n",
        "    return {\n",
        "        'english_2_gram_length': len(lm('en', 2, True)),\n",
        "        'english_3_gram_length': len(lm('en', 3, True)),\n",
        "        'french_3_gram_length': len(lm('fr', 3, True)),\n",
        "        'spanish_3_gram_length': len(lm('es', 3, True)),\n",
        "    }\n",
        "\n",
        "def test_eval():\n",
        "    return {\n",
        "        'en_en': eval(lm('en', 3, True), 'en', 3),\n",
        "        'en_fr': eval(lm('en', 3, True), 'fr', 3),\n",
        "        'en_tl': eval(lm('en', 3, True), 'tl', 3),\n",
        "        'en_nl': eval(lm('en', 3, True), 'nl', 3),\n",
        "    }\n",
        "\n",
        "def test_match():\n",
        "    df = match()\n",
        "    return {\n",
        "        'en_en_3': df[(df['source'] == 'en') & (df['target'] == 'en') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_tl_3': df[(df['source'] == 'en') & (df['target'] == 'tl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_nl_3': df[(df['source'] == 'en') & (df['target'] == 'nl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "    }\n",
        "\n",
        "def test_generate():\n",
        "    return {\n",
        "        'english_1_gram': generate('en', 1, \"I\", 20, 5),\n",
        "        'english_2_gram': generate('en', 2, \"I am\", 20, 5),\n",
        "        'english_3_gram': generate('en', 3, \"I am\", 20, 5),\n",
        "        'english_4_gram': generate('en', 4, \"I Love\", 20, 5),\n",
        "        'spanish_2_gram': generate('es', 2, \"Soy\", 20, 5),\n",
        "        'spanish_3_gram': generate('es', 3, \"Soy\", 20, 5),\n",
        "        'french_2_gram': generate('fr', 2, \"Je suis\", 20, 5),\n",
        "        'french_3_gram': generate('fr', 3, \"Je suis\", 20, 5),\n",
        "    }\n",
        "\n",
        "TESTS = [test_preprocess, test_lm, test_eval, test_match, test_generate]\n",
        "\n",
        "# Run tests and save results\n",
        "res = {}\n",
        "for test in TESTS:\n",
        "    try:\n",
        "        cur_res = test()\n",
        "        res.update({test.__name__: cur_res})\n",
        "    except Exception as e:\n",
        "        res.update({test.__name__: repr(e)})\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(res, f, indent=2)\n",
        "\n",
        "# Download the results.json file\n",
        "files.download('results.json')\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "kCksAA6RisRQ",
        "outputId": "92a6a40c-ff55-4f76-b479-b6b60a2182c2"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ffcb544-8e3c-4543-afcd-e86c4bedbd8d\", \"results.json\", 942)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Apr 16 12:06 data\n",
            "-rw-r--r-- 1 root root  942 Apr 16 13:23 results.json\n",
            "drwxr-xr-x 1 root root 4096 Apr 12 13:22 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMSfgUtuiux0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}