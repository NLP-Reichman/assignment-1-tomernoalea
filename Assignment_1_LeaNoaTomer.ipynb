{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "FECp14-d_F2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NLP-Reichman/assignment_1.git\n",
        "!mv assignment_1/data data\n",
        "!rm assignment_1/ -r"
      ],
      "metadata": {
        "id": "za-DgcYB_IQx",
        "outputId": "a7c31492-533c-4c8c-8499-b5d5bf0ba477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment_1'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (58/58), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 150 (delta 42), reused 33 (delta 25), pack-reused 92\u001b[K\n",
            "Receiving objects: 100% (150/150), 6.79 MiB | 17.77 MiB/s, done.\n",
            "Resolving deltas: 100% (63/63), done.\n",
            "mv: cannot move 'assignment_1/data' to 'data/data': Directory not empty\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this assignment you will be creating tools for learning and testing language models. The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n",
        "The relevant files are under the data folder:\n",
        "\n",
        "- en.csv (or the equivalent JSON file)\n",
        "- es.csv (or the equivalent JSON file)\n",
        "- fr.csv (or the equivalent JSON file)\n",
        "- in.csv (or the equivalent JSON file)\n",
        "- it.csv (or the equivalent JSON file)\n",
        "- nl.csv (or the equivalent JSON file)\n",
        "- pt.csv (or the equivalent JSON file)\n",
        "- tl.csv (or the equivalent JSON file)"
      ],
      "metadata": {
        "id": "0i2bOXTB8Dvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "1u1qR7iaq_GU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import collections\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "IHN0tWTurwkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "Implement the function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. Our token definition is a single UTF-8 encoded character. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data.\n",
        "\n",
        "Note - do NOT lowercase the sentences in whi HW."
      ],
      "metadata": {
        "id": "i56aKA0K8adr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tweet_texts(file_path: str) -> list[str]:\n",
        "  with open(file_path, 'r', encoding='utf-8') as file:\n",
        "    content = file.read()\n",
        "    data = json.loads(content)\n",
        "    tweet_texts = data['tweet_text'].values()\n",
        "\n",
        "  return tweet_texts\n",
        "\n",
        "\n",
        "def preprocess() -> list[str]:\n",
        "  '''\n",
        "  Return a list of characters, representing the shared vocabulary of all languages\n",
        "  '''\n",
        "  vocabulary = set()\n",
        "\n",
        "  for filename in os.listdir('/content/data'):\n",
        "        file_path = os.path.join('/content/data', filename)\n",
        "        if file_path.endswith('.json'):\n",
        "          tweet_texts = get_tweet_texts(file_path)\n",
        "          for tweet in tweet_texts:\n",
        "              vocabulary.update(tweet)\n",
        "\n",
        "  vocabulary.update(['×', '×ª'])\n",
        "\n",
        "  return list(vocabulary)\n",
        "\n",
        "print(preprocess())"
      ],
      "metadata": {
        "id": "ws_5u7vRrg0o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da0d4782-b09a-431b-9d8b-3af9b7bb4e48"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ìŠˆ', 'â”»', 'ê³¼', 'ğŸµ', 'â†›', 'ğŸ˜†', 'â‹…', 'â–¶', 'ğŸ”˜', 'ğŸ“Š', 'å½±', 'â™©', 'í—Œ', 'ë§¨', 'ğŸ˜¨', 'ğŸ“»', 'â™¡', 'í„°', 'Ì', 'ğŸ¤™', '^', 'æŒ¨', 'åˆ', 'ğŸ’ƒ', 'â€ ', 'âœŠ', 'â—†', 'Ë˜', 'ï½', 'Â©', 'ğŸ™', 'ì œ', '\\u2066', 'Â½', 'ğŸ†', 'í—¨', 'ğŸ®', 'â¥', 'ï¼½', 'ğŸ“Œ', 'ë£°', 'ğŸŒ…', 'Ë¡', 'ä¸–', 'Ğœ', 'ï¿¼', 'ì—£', 'à¼»', 'ã†', 'ğŸ‡­', 'ğŸ”›', 'ğŸˆµ', 'à¸–', 'ì—°', 'ğŸŒ’', 'â€œ', 'â', 'ğŸ˜œ', 'é‚£', 'ğŸ’¢', 'ğŸ¯', 'ä¸­', 'ğŸ­', 'ğŸš¨', 'â', 'âœ³', 'ğŸ”', 'ï½š', 'à¸™', 'ğŸ’œ', 'ìœ¤', 'ë³¸', 'Ã’', 'ë±€', 'ìœ ', 'ğŸ¦', 'ğŸš—', 'ğŸŒ½', 'ê°“', 'ğŸŒ', 'â•´', 'ğŸ™', 'í˜„', 'Ğ½', 'ğŸœ', 'â—‘', 'ÙŠ', 'H', 'â™»', 'à¸¸', 'ğŸ¤‘', 'ğŸ¢', 'ğŸ¥…', 'ğŸ˜‚', 'ğŸ”µ', 'ğŸ´', 'âœ´', 'áµ—', 'ğŸ¸', 'â™', 'â˜“', 'v', 'ğŸ‡¾', 'ğŸ¥', 'Ï‰', 'à¸—', 'A', 'Â²', 'âœ¶', 'ğŸ”¹', 'ğŸ”', 'Âº', 'ã‚´', 'ğŸ½', 'q', 'ğŸ’€', 'ğŸ›´', 'ğŸ¤', 'ğŸ£', 'Ñ', 'ğŸ™Œ', 'å…ˆ', 'ë²„', 'â›„', 'ğŸ’‘', 'ì‹¸', 'ğŸŸ', 'u', 'Ï…', 'ğŸŒ', 'ğŸ¦', 'Ã«', 'æ–‡', 'ğŸ†', 'ğŸˆ·', 'ğŸ…°', '/', 'ã­', '}', 'ã', 'ğŸ™‰', 'ç”»', 'ã…', 'ï¼¬', 'ğŸ‘†', 'Ğ¿', 'ğŸ˜˜', 'â–”', 'ë‘', 'à¸£', 'ë“œ', 'â€¢', 'à¼', 'âŒ', 'ì‚¬', 'íŒŒ', 'Å’', 'â˜†', 'ğŸ', 'ğŸŒ¥', 'Ğ³', 'â¸…', 'áµ›', 'à¸¢', 'å§¿', 'ì˜', 'ğŸ¯', 'ã›', 'Ø©', 'â·', 'ğŸš¼', 'â›³', 'ğŸ´', 'ğŸ˜«', 'ã„', 'ğŸ‘º', 'â°', 'ğŸ“¬', 'à¸¨', 'W', 'â–¼', 'ğŸ‡§', 'Ğ ', 'ğŸª', 'áµ–', 'â˜‘', 'ì˜¨', 'ğŸ˜¢', 'ğŸ‘–', 'ğŸ¥‚', 'Ùˆ', 'ğŸ‘‚', 'ğŸ–¼', 'ğŸ˜¦', 'ğŸ‘“', 'âš–', 'ë„·', 'ãƒ', 'ğŸŸ', 'ë‘', 'ğŸ', 'æœ', 'ğŸ¥', 'ğŸ¤³', 'Â·', 'â†’', 'Ã', 'Â«', 'ğŸ†˜', 'ğŸ””', 'â™‹', 'âœ–', 'ğŸ‘', 'ãƒ¦', 'ğŸš²', 'ğŸ‘„', 'ğŸ¤–', 'â—•', 'ğŸ’—', 'ğŸ•ª', 'â•', 'ğŸ”ƒ', 'ğŸ”', 'ë²…', 'ë¯¼', 'Â§', 'ğŸ¤¡', 'ğŸ¢', 'ğŸ’©', 'ğŸ¥', 'ğŸ’', 'Ù‡', 'ğŸš¶', 'à¤—', 'Ø³', 'ê·¸', 'ëœ', 'Ø·', 'Ğ±', 'âš•', 'ì…˜', 'â™', 'ã«', 'ğŸ‹', 'ìŠ¹', 'ğŸ’¤', 'ğŸ•·', 'ğŸ’', 'å„¿', 'ï½¡', 'â‹', 'ì©œ', 'ãƒ’', 'ï¸µ', 'â˜›', 'ãª', 'ğŸ‘²', 'ê²©', 'Ì¥', 'ğŸšµ', 'ğŸŒ´', 'ğŸ‘', 'íƒ€', 'ğŸ’¦', 'Ì®', 'ê°€', 'Í¡', 'Ò¯', 'ë¸', 'ğŸ‘ª', 'ğŸ†’', 'ï½ƒ', 'ğŸ“›', 'â°', 'Ë›', 'ğŸš”', 'ğŸ¥„', 'ğŸ™‡', 'â–³', 'Ã', 'Å', 'Ã­', 'â‰¦', 'â˜', 'ğŸŒ«', 'å¥½', 'ğŸ˜ƒ', 'ë„¤', 'ğŸ’”', 'ğŸŒª', 'áµƒ', 'â‰¤', 'Ø®', 'âœ', 'ï½…', 'íŒ¨', 'ğŸ‘µ', 'ğŸ', 'Ø±', 'Ğ', 'ğŸ¤š', 'ë¹…', 'Ñ', '\\\\', 'Ì€', 'ğŸ·', 'â—½', 'ğŸŒ»', 'ğŸ±', 'ï¿½', 'ì†¡', 'ğŸ“·', 'ãƒ‰', 'ìƒ¤', 'ğŸ¼', 'âœµ', 'ã€Š', 'Æ’', 'â', 'Ù„', 'âˆ', 'ğŸ‘­', 'â–£', 'Ê–', 'â•­', 'ğŸ³', 'à¸¡', 'ğŸ˜', 'Å', 'ë‹¹', 'ğŸ‘Œ', 'â’', 'Ø«', 'ğŸ¤¢', 'ğŸ¥€', '2', 'ï¼®', 'ğŸ“¼', 'ê²½', 'ì¸ ', 'ï¼«', 'à¤¸', 'ğŸ¥”', 'ğŸ¤', 'âŒ', 'ğŸ…¾', 'â€', 'ğŸ˜°', 'â˜°', 'â—', 'ğŸ¦', 'c', 'æ’ƒ', 'ğŸŒ¼', 'à¸', 'â˜”', 'ğŸ•º', 'çµ‚', 'ìš”', 'â–¿', 'ë ›', 'ğŸ ', 'ğŸƒ', 'âˆ€', 'Â¶', 'ğŸ½', 'â•±', 'ğŸ—', 'âˆš', 'ğŸ’', 'ê²€', 'à¸±', 'ğŸ ', 'ìƒ', 'ã‚»', 'ğŸ–', 'Ùƒ', 'ì‹', 'K', 'ğŸŒ¿', 'ğŸ¤', 'âš¾', 'ğŸ’Ÿ', 'â', 'ğŸ‡', 'ğŸ‡¯', 'ğŸ¤£', 'ÅŸ', 'ğŸ˜…', 'Ã‘', 'ğŸ¾', 'ã€œ', 'ğŸ‘§', 'ğŸƒ', 'í…', 'ğŸ˜¼', 'ğŸ‘¶', 'ç³Ÿ', 'ğŸ¤—', 'ğŸ˜€', 'ğŸ’­', 'ğŸ', 'ãƒ¡', 'í•´', 'âœ…', 'ğŸˆ', 'âœ¡', 'ï¼Š', 'ğŸ’£', 'â–º', 'â”“', 'Ğ', 'ğŸ‡·', 'Íœ', 'ğŸ”´', 'ì™¸', 'ã¿', 'ğŸ˜’', 'å’', 'Ìƒ', '\\x80', 'ï½™', 'âœ‚', 'ğŸ’¿', 'ğŸ”½', 'ğŸ˜ˆ', 'â’', 'ë‹¨', 'ğŸ‘', 'íƒ„', 'ì°°', 'ğŸ’Œ', 'â €', 'à¸µ', '-', 'ğŸ¼', 'Ã ', 'ğŸ‡¿', 'ë½', 'í”¼', 'Ã¤', 'ğŸŒº', 'ì½”', 'é–“', 'ì¢…', 'ğŸ“', 'àº¶', 'ğŸŒ', 'ğŸ‘•', 'Ã³', 'ğŸ“°', 'æ°—', 'ğŸ¦‰', 'ğŸ‰', 'Ã»', 'à¥‡', 'ìŠ¬', 'äºº', 'ğŸ™‚', 'ğŸ˜¹', 'ğŸš', 'Ã¨', 'ğŸ©', 'ğŸš', 'â¬…', 'ì´', 'ğŸ˜', 'E', '+', 'ãŸ', 'ğŸ—', 'ğŸš«', 'ë¦¼', 'ğŸ·', 'r', 'â†¯', 'ã€', 'êµ¬', 'ë²¨', 'ğŸ”™', 'ï¼²', 'ğŸ’†', '6', 'ğŸ“½', 'ì¬', 'à¸š', 'ğŸ˜', 'ğŸ”‘', 'ã……', 'Ø¢', 'â˜ ', 'ğŸ‘£', 'ğŸ’', 'â˜¼', 'âŸ', 'ã—', 'ğŸ‘¸', '\"', 'ğŸš€', 'ã…ˆ', 'â˜', '4', 'L', 'ï¼¦', 'í† ', 'ğŸ¿', 'â™£', 'ğŸšŒ', '~', 'å¢—', 'ğŸ‘', 'ğŸ”œ', '×', 'ğŸ¬', 'ğŸ’', 'â€°', 'âŒ›', 'ğŸ‘¼', 'i', 'Ã‰', 'Ò’', 'ğŸ•¤', 'âœ§', 'Ğ¤', 'ğŸ“', 'â”—', 'ï¼ƒ', 'ğŸ‘®', 'ë·”', 'â”›', 'à¸›', 'â—', '.', 'Ê•', ',', ';', 'ğŸ–', 'ğŸ–’', 'â˜®', 'ğŸ’', 'æ­³', 'ã‚', 'æ‹¶', 'Ã©', 'ã²', 'à¥', 'â•š', 'ë¯¸', 'ğŸ¸', 'Âª', 'ï¼‚', 'ğŸŠ', 'ï½—', '0', 'â˜', 'ğŸ“¯', 'ğŸ¦', 'í˜', 'ğŸ”', 'åˆ†', 'à¸§', '\\u2069', 'â›…', 'âœ', 'ï¼¶', 'ã…œ', 'z', 'íƒ‘', 'ğŸ™†', 'ğŸ»', 'Å„', 'âˆ', 'ã‚©', 'ğŸ²', 'â¤', 'ğŸ•', 'ğŸŒ†', 'm', 'ÛŒ', 'í”„', 'â•¯', 'ãƒ»', 'ğŸŒœ', 'V', 'Ã‡', '\\x9d', 'è¾¼', 'ë‹ˆ', 'â„…', 'Â¡', 'ğŸ™Š', 'ğŸ™€', 'ğŸš‡', 'ğŸ»', 'b', 'â–•', 'ì„¸', 'ğŸ±', 'ë§ˆ', '\\u2067', 'Ã¢', 'ë³´', 'â€¿', 'ã…¤', 'ğŸ”¨', 'ğŸ˜ ', 'é­', 'ğŸ±', 'ğŸ”“', '?', 'ğŸ•µ', 'ã¥', 'ğŸ†™', 'ğŸ‘¥', 'âŒ£', 'ê¸ˆ', 'ğŸ’®', 'í¬', 'Î©', 'ğŸ¨', 'à¸‡', 'ğŸ”', 'æ¥­', 'ì„', 'ğŸ«', '|', 'ğŸ”»', 'ìµœ', 'ğŸ…±', 'ì„ ', 'ğŸ¦‘', 'ğŸ¢', 'â¤µ', 'ë™', 'ğŸ‘ˆ', 'ğŸ©', 'í›ˆ', 'ãƒ†', 'ğŸº', 'C', 'ï½•', 'â“˜', 'ğŸŒ¸', 'â€»', 'ì—', 'ë°±', 'ë°©', 'ã‚‰', 'ğŸ‘™', 'Ã®', 'â˜¾', 'ğŸ˜±', 'ã‹', 'ğŸ¦‡', 'ã€‚', 'â–¦', 'ì½˜', 'ğŸ“€', 'ğŸ˜·', 'ğŸŒ²', 'â­', 'â˜…', 'ãƒ„', 'ğŸ‡²', 'â˜„', 'ğŸ•¯', 'ğŸ—³', 'â³', 'S', 'ğŸŒƒ', 'ğŸ€', 'â—¾', 'ğŸ¯', 'â™', 'â”†', 'ğŸ“§', 'ï¼¥', '&', 'ã€†', 'í•¸', 'ëˆ„', 'ä¸»', 'ğŸ˜¯', 'ğŸ˜­', 'ğŸ˜»', 'ä»˜', 'ë¡±', 'ğŸ‘Š', 'Ä—', 'â”', 'ë‚˜', 'á¶œ', 'â™', 'â˜š', 'ğŸ”©', 'áµ’', 'ì¥', 'ï¼¨', 'Ù', 'í•‘', 'ğŸ¤¥', 'ğŸ¹', 'ğŸŒ„', 'ãƒ½', 'ï¼­', 'ğŸµ', 'Ğ²', 'ï½‰', 'ã‚ª', 'ğŸœ', 'â•¦', 'ğŸŒ“', 'ã¦', 'â•¬', 'ì²œ', 'ï¼‰', 'Î”', 'ã€‹', 'ğŸ', 'ğŸ‘±', 'Ãœ', 'ğŸ¤ ', 'å…', 'ìƒµ', 'Â¸', 'ãƒ¼', 'ğŸ¥', 'Ñ€', 'ğŸŒš', 'ğŸ˜', 'ğŸ‹', 'â›ª', 'ë”', 'ï¾‰', 'åˆ¹', 'ï½', 'â', 'ğŸŒŠ', 'Ìˆ', 'ì½¤', 'åˆ¶', 'â‰§', 'âœŒ', 'ç¹‹', 'G', 'Ñ', 'ğŸ“', 'â€“', '\\u200d', 'ğŸ‘¯', 'æ‰‹', 'â—ˆ', 'ğŸ’', 'ğŸŒ™', 'ğŸ™', 'â˜¹', '\\u200a', 'ì˜ˆ', 'Ì¯', 'ë£Œ', 'ĞŸ', 'ğŸ‚', 'ğŸ‘', 'áµ', 'â†š', 'ğŸ”‚', 'â“‚', 'ğŸ‘°', 'ğŸ¦ƒ', 'ğŸ¤’', 'ï¼±', 'ğŸ‘¦', 'ğŸ‡µ', 'â„¢', 'âœ­', 'ğŸ˜µ', 'à¸ˆ', 'â™ª', 'ğŸ©', 'ğŸŒ', 'ğŸš»', 'ğŸ’–', 'ğŸ›³', 'ğŸ—£', 'ã‚‹', 'ğŸ““', 'ğŸ“¦', 'ğŸ¤“', 'Ø§', 'Ã€', 'ï¼', 'ğŸ', 'Â»', 'â„', 'Ø¹', 'â˜‰', 'ğŸ“¸', 'äº’', 'áµˆ', 'ì¸', 'ã¨', 'ğŸ†“', 'ğŸ”‹', 'ğŸ¿', 'â†©', 'ê±¸', 'â–', 'â“¦', 'ğŸ’•', 'í˜¸', 'ğŸ’¬', 'ëŸ°', 'à¸', '!', 'ê²Œ', 'ğŸ—½', 'â€¼', 'âš’', '[', 'â›©', 'h', 'ğŸ˜¡', 'èŠ±', 'ğŸ¹', 'ğŸ', 'âœ', 'ğŸ’¸', 'ğŸ˜©', 'ğŸŒ¾', 'â€¦', 'ì§„', 'ğŸš´', 'Å ', 'Ğ', 'â”ƒ', 'ë¸Œ', 'ë§¤', 'ğŸ’™', 'ì•¼', 'ê³ ', 'ì˜', 'ğŸ‘¤', 'ğŸ”¸', 'ã‚­', 'Ê·', 'â˜€', 'ï½Œ', 'ì¹´', 'ã… ', 'ğŸ‘¹', 'ì§', 'ï¼“', 'Ğ¯', 'èœ', 'ğŸ˜', 'ç›¸', 'ğŸ“¡', 'æ­Œ', 'é¢¨', '\\u31ef', 'â—¡', 'â•—', 'ğŸ', 'ã€', 'ğŸ’', 'Ëš', 'Ä°', 'ğŸ…', 'n', 'âœƒ', 'ï½‚', 'Ã”', ')', 'ã‚Œ', 'â†”', 'ã‚Š', 'ğŸ—¾', 'ğŸ„', ' ', 'â˜ƒ', 'âœ', 'ãƒ', 'çœŸ', 'ğŸ’¯', 'ğŸ˜®', '$', 'ğŸŸ', '>', 'Ê¸', 'Ë–', 'ç¬', 'ìƒ', 'â„ƒ', 'ğŸ’°', 'ğŸŒ', 'ğŸ¾', 'ÃŒ', 'ğŸ¤›', 'ğŸ“š', 'ğŸ”¶', 'ãƒ‘', 'ã…£', 'ì„', 'Ğº', 'ğŸ°', 'í‚¤', 'ì‹ ', 'ğŸ”ª', 'ğŸ', 'ğŸ¾', 'I', ':', 'ğŸ“¢', 'ğŸ›€', 'ï·»', '5', 'ì…”', 'ì² ', 'ì–´', 'ï¼¿', 'ğŸº', 'â—', 'ğŸŒŒ', 'âœ©', 'ë²•', 'ã‚µ', 'Ñ‚', 'ğŸ‘', 'à¤°', 'í—¤', 'í¬', 'ğŸ', 'ğŸ’¨', 'Ä±', 'ï¼¡', '\\xad', 'ã‚‡', 'ì­', 'g', 'ğŸ‘…', 'Ğ·', 'Ã•', '1', 'âˆµ', 'ğŸ•Œ', '7', 'ğŸ’³', 'Ê³', 'ğŸšˆ', 'ğŸ’¼', 'â–ª', 'â ', 'æ™‚', 'Ø¬', 'âŠ™', 'ğŸ¥', 'ï½‡', 'ì•ˆ', 'ğŸ•’', 'ãƒ–', 'â’', 'ğŸ˜Š', 'Ù‚', 'ë¨', 'åƒ', 'ğŸ†‘', 'ğŸ«', 'â†º', 'ğŸ›ƒ', 'ğŸ¥', 'ãƒ—', 'à¸­', 'ã‚¸', 'Ã°', 'ã€°', 'âŒš', 'ì „', 'ğŸ’ˆ', 'ãƒ¥', 'Ãš', 'ï¼µ', 'ğŸ™‹', 'ãœ', 'T', 'â”„', 'áµ‰', 'ï½˜', 'ğŸŒ±', 'à¸°', 'ì‹¤', 'Ã¡', 'ğŸš‘', 'â™¯', 'Ã—', 'à¸ ', 'â”', 'ğŸ¤”', 'ğŸ‘‘', 'â˜ª', 'ê¹€', 'ğŸ¤´', 'Î˜', '\\U000fe4e6', 'U', 'ï¼°', 'Ù†', 'ë‚¨', 'ğŸ˜¸', 'Ã‹', 'à¤ª', 'ğŸ›©', 'D', 'ğŸ‡º', 'ğŸ’', '*', 'á¶¦', 'æ˜ ', 'á™“', 'ğŸ˜“', 'ãƒ“', 'å†™', 'ãƒ”', 'â‘ ', 'ï½‘', 'í•˜', 'í˜•', 'Ø¦', 'j', '%', 'ã‚¹', 'ğŸš¦', 'ğŸ§', 'ï¼£', 'ğŸ‡«', 'å…¥', 'ğŸ°', '\\x92', 'ğŸ˜š', 'Â¤', 'ğŸ”®', 'ğŸš£', 'Ğ´', 'ì˜¤', 'ğŸ‘‹', 'ã‚¯', 'Ã¶', 'âš“', '×ª', 'â†“', 'ğŸ', 'ë…¸', 'ğŸ„', 'ğŸ’‚', 'â–', 'ã', 'ğŸŒŸ', 'â‰', 'ë„', 'Ã¬', 'ï¼³', 'ğŸ’‰', 'P', 'ëª¬', 'ğŸ˜•', 'â†•', 'ğŸ¤·', 'ğŸ’¶', 'ğŸ¶', 'í•œ', 'ë™', 'F', 'ì§€', 'â€•', 'ğŸ¥ƒ', 'ğŸ¿', 'æ´¸', 'å‹•', 'Ãµ', 'á¶°', 'â–½', 'ëŒ€', 'â”€', 'â€º', 'ï¹ª', 'åŠ›', 'ğŸ“©', 'ï¸', 'à¹‘', 'ğŸš§', 'ğŸ§', 'â”³', 'íŠ¸', 'ë´‰', 'ğŸ‡', 'ì´ˆ', 'ğŸŒ¹', 'ğŸ¡', 'ğŸš™', 'ë°•', 'R', 'ì—­', 'ğŸ…', 'â‰¥', 'ë¦‰', 'âˆ†', 'æ©Ÿ', 'ğŸ’ª', 'â€™', 'ğŸŒ¨', 'à¼º', 'ğŸ˜¿', 'â™›', 'æ’®', 'à·´', 'd', 'ğŸ…', 'â±', 'ğŸ•›', 'ãƒ ', 'â—»', 'ğŸ’˜', ']', 'á´¬', 'ë‘‘', 'ãƒ¬', 'ì£¼', 'ğŸ‘', 'ğŸš“', 'æ—', 'ğŸ—»', 'áµ˜', 'â’', 'Â®', 'âƒ£', 'é€š', 'Ã¼', 'â›', 'â”', 'âœ°', 'ğŸ', 'æŠ•', 'ğŸ”…', 'â˜½', 'ã®', 'â¸„', 'â˜º', 'ë¹¼', 'ëŠ”', 'Ä', 'ğŸ‹', 'ğŸ‘¨', 'ğŸ–¥', 'ğŸŒ¯', 'N', '(', 'ê°•', 'â›ˆ', '8', '\\x91', 'ë ˆ', 'ğŸ—¡', 'ğŸ¥˜', 'ç‹', 'ğŸ«', 'âšœ', 'ï½¥', 'ğŸ‡¨', 'â¸', 'ï½œ', 'Ğ¸', 'ğŸ', 'ğŸ†—', 'ì— ', 'ğŸ•¶', 'â–’', 'âš ', 'ï¼˜', 'ğŸ‡©', 'èµ«', 'ğŸ–¤', 'â™¥', 'âœ‹', 'å«Œ', 'ì¦ˆ', 'ğŸ·', 'Ñ…', 'å­¦', 'ã€', 'ã…‹', 'ğŸ•œ', 'ë…„', 'Ğ»', 'ğŸ“´', 'ğŸ¡', 'åˆ©', 'Ã¸', 'ğŸ°', 'ğŸ¾', 'ğŸš¬', 'Â¯', 'â™', 'ì¶œ', 'w', 'ğŸ”’', 'ğŸ˜´', 'ğŸŒ·', 'ï¼—', '_', 'ğŸ¬', 'ğŸ†”', 'ìœ„', 'í€', 'ìŠ¤', 'ğŸ˜‰', 'â‹­', 'åˆ', 'ğŸ˜¶', 'â—', 'ğŸ‰', 'ğŸ’…', 'ç•Œ', 'ğŸ––', 'ğŸŒ—', 'à¹€', 'âš', 'ğŸª', 'ğŸ­', 'ã¯', 'ğŸš', 'ã€‘', 'ê·œ', 'ğŸ“¿', 'à¹‰', 'â™‚', 'á´—', 'ğŸŒ ', 'ğŸ¦€', 'â', 'â€', '\\u2009', 'êµ­', 'ğŸ˜£', 'ì••', 'ğŸº', 'è¸Š', 'â‹ª', '=', 'ğŸ…¿', 'ãƒ®', 'ğŸ', 'ğŸŠ', 'â˜•', 'ğŸ“', 'â–™', 'ë‚´', 'ğŸ™„', 'ğŸ™ˆ', 'ã‚«', 'à¤‚', 'ğŸ›«', 'ë…€', 'å½¡', 'ğŸ›¬', 'ğŸ“', 'â—„', 'â€”', 'ğŸ’½', 'ğŸ”‰', 'à¸¹', 'è®¸', 'âœ“', '{', 'ğŸ‡¼', 'ğŸ”Œ', 'â˜œ', 'ï½’', 'x', 'ğŸ“–', 'í‚¹', 'â€˜', 'íŒ', 'ğŸˆ¶', 'ğŸ‘©', 'â‡¨', 'âœ”', 'ğŸ”', 'ğŸ¤¦', 'ã‚³', 'â‹', 'Ø¨', 'Ñ‹', 'íƒœ', 'ãƒ', 'ğŸ”²', 'ì—¬', 'ç©º', 'ìŠ¨', 'ã‚¤', 'ğŸ“º', '<', 'ã…¡', 'Z', 'ğŸ¦„', 'ê ', 'ğŸ•˜', 'â£', 'k', 'ğŸŒ', 'â†˜', 'ì• ', 'â¬‡', 'Ø´', 'l', 'Ã²', 'ğŸ“', 'ğŸ™…', 'ë¦„', 'ğŸ¬', 'ğŸŒ¬', 'ï¼´', 'ğŸ˜¤', 'âœ¿', 'ğŸ“…', 'ğŸ“‚', 't', 'ãˆ', 'â–Š', 'ã£', 'ê¼¼', 'ğŸ¸', 'çµ', 'ğŸ•Š', 'ãƒ­', 'ğŸ‡¦', 'ğŸ“‹', 'ğŸ–', 'o', 'ë„ˆ', 'ã‚§', 'e', 'ãƒ', 'Ãƒ', 'Å“', 'ëŸ¬', 'â€', 'â“™', 'ê¸°', 'âšª', 'ì„¹', 'â˜™', 'â™€', 'ğŸ¿', 'ğŸ‡´', 'âš¡', 'ì¼', 'ï¹', 'ğŸƒ', 'âˆ‡', 'Ø­', 'ì¿±', 'ğŸ‘‡', 'ì—‘', 'â˜£', 'ë²³', 'í†¡', 'Û¶', 'ï¼Ÿ', 'Â¨', 'ğŸ“', 'ğŸ¨', 'ğŸ‡', 'ì›', 'ï½', 'ğŸ—‚', 'ğŸˆ', 'ç¨¿', '#', 'ğŸ“', 'B', 'â€²', 'â‚¹', 'à¤•', 'ğŸ¹', 'æ‚ª', 'ì ¤', 'ãƒ©', 'Ãº', 'ï¼–', 'a', '\\x7f', 'ğŸŒ¶', 'â™¬', 'â™“', 'â±', 'à¼¼', 'ğŸ¼', 'ì •', 'ğŸ¦‹', 'ğŸ¤•', 'Ø²', 'à¸•', 'ï½€', 'ë¹„', 'ë¼', 'â¤', 'â†—', 'ğŸš¢', 'ï¼¤', 'y', 'ğŸ’¡', 'ğŸ‘¡', 'Ê°', 'ğŸ†–', 'ğŸ’„', 'ğŸ˜Ÿ', 'â¦‘', 'â•²', 'ğŸ“£', 'ğŸ¤˜', 'ğŸ³', 'ğŸ’¥', 'â•°', 'ãƒ‹', 'ğŸˆ', 'á¶ ', 'ğŸŒ³', 'å‘Ÿ', 'çŸ¥', 'Ø°', 'ãƒŠ', 'ğŸŒ‹', 'ğŸ”¥', 'Ã“', 'ğŸ˜”', 'Ğ°', 'â‚¬', 'ï¼¯', '9', 'Y', 'ğŸŒ®', 'ë“€', 'ğŸ™', 'ğŸ‡', 'æ´²', 'ğŸŒ§', 'ğŸ¤œ', 'ï½–', 'â¢', 'ì™•', 'Â´', 'ğŸ˜‹', 'Ã™', 'ğŸŒ€', 'ãƒˆ', 'Ğ¾', 'ğŸ’', 'ğŸŒ‡', 'â¿', 'ãŠ', 'â—¼', 'âœˆ', 'ğŸ‡¬', 'Ãˆ', 'å¾Œ', 'ì–‘', 'ì±„', 'ğŸš', 'ğŸ¤', 'ğŸ‰', 'Ğµ', 'â’‘', 'ğŸ˜Œ', 'Ê”', 'á´°', 'ëŠ˜', 'Ã…', 'ï½', 'ğŸ˜‘', 'â‹', 'ğŸ”', 'ë„', 'ì—˜', 'ğŸ•', 'ìš©', 'ë² ', 'ğŸ“ˆ', 'Ã¹', 'ğŸ—', 'ğŸ‘³', 'í’€', 'Ã±', 'â©', 'ì¹˜', 'ë¡œ', 'ãŒ', 'â', 'ğŸ’µ', 'Ã¯', 'â™«', 'ã‚€', 'ÃŠ', 'ì‚´', 'ğŸ³', 'í”Œ', 'ğŸ¹', 'Â°', 'ë¸”', 'ã‚°', 'ğŸ™', 'â–¸', 'ğŸ˜¥', 'ğŸ‘', 'ğŸ®', 'X', 'ğŸ˜', 'ğŸ˜›', '\\u200b', 'ğŸ‘ ', 'ğŸ‡³', 'ğŸ“²', 'à¸´', 'ğŸ ', 'ì•„', 'Q', 'Â£', 'ğŸ¡', 'â‘¥', 'Øº', 'ë¦¬', 'ğŸ’»', 'âœ¨', 'ê³¡', 'ğŸ£', 'ğŸ˜‡', 'â¡', 'â“', 'ğŸ™', 'ğŸ½', 'ï¼©', 'ğŸ‡»', 'ì™€', 'à¤¾', 'ì¶”', 'ğŸ˜–', 'ì‹œ', 'ğŸ¶', 'ë¬´', 'áµ', 'Øª', 'â›“', 'ì…©', 'J', 'ğŸ¥Š', 'ğŸ‘»', 'ğŸ˜', 'ğŸ¼', 'ğŸ«', 'Ğ¼', 'ğŸš˜', 'â—‡', 'ï¼·', 'à¸²', 'ğŸ¤§', 'í™˜', 'ğŸ‘‰', 'ğŸ€', 'âš˜', 'ğŸ­', 'ì‚¼', 'âš”', 'ğŸ¨', 'ğŸ—“', 'â˜¯', 'ğŸŸ', 'ÄŸ', 'ğŸ‘«', 'ğŸ‡ª', 'ë””', 'ï¼§', 'Ã§', 'Ã£', 'ë°”', 'ğŸ‘¿', 'ğŸ“†', 'ğŸŒ°', 'ğŸ‡¸', 'ã€Œ', 'ğŸ˜¬', 'â–', 'O', 'ğŸ—', 'ğŸ¥’', 'à¸”', 'ğŸŒˆ', 'â›”', 'ğŸ›„', 'Ãª', 'ì»¤', 'ğŸ†', 'ê²°', 'ï½„', 'ğŸ‘Ÿ', 'ï¼»', 'ğŸš®', '`', 'âœ', 'ğŸ›°', 'Ã–', 'â¦’', 'ì˜', 'ã‚¨', 'Ã´', 'â™¤', 'à¸‚', 'ğŸ»', 'ğŸ‰', 'æœ¬', 'ğŸ’«', '\\u3000', 'ï¼¹', 'ğŸ•Ÿ', 'Å¸', 'ãƒ¯', 'à¤¬', 'ğŸ“¹', 'è¡Œ', 'Ñƒ', 'ğŸ€', 'âš«', 'ğŸŒµ', '@', 'ë°€', 'ğŸ¤', 'ğŸ˜²', 'à¸¥', 'â', 'Ğ¦', 'â–ˆ', 'M', 'ì°Œ', 'ã‚¿', 'ğŸ€', 'ãƒ§', 'ğŸ•', 'ï½“', 'í™”', 'ğŸ‚', 'ï¼ ', 'ğŸ˜½', 'â†‘', 'ë£¸', 'ğŸ”°', 'ğŸš©', 'ğŸŒ', 'â‡˜', 'ï½', 'ã€', 'âœ·', 'Â¥', 'ë§', 'â™¦', 'ë“±', 'ãƒ³', 'ğŸ‘—', 'âŠ', 'ì†Œ', 'Ã', 'ğŸ”«', 'ğŸš¿', 'à¹', 'ãƒƒ', 'âš½', 'å½¼', 'ğŸ’§', 'ğŸ†š', 'ã§', 'ğŸš–', 'Ø¶', 'ğŸ“±', 'ğŸŠ', 'â†', 'ìš°', 'ğŸ˜§', 'ğŸ‚', 'ğŸ²', 'ğŸ‡±', 'â•‘', 'âˆ´', 'ğŸ’“', 'ë³µ', 'ğŸ‡½', 'ã‚’', 'ğŸ', 'ì§‘', 'ğŸ°', 'ë…¼', 'â“¢', 'â•©', 'è€…', 'ğŸ”º', 'ï¼ˆ', 'æŸ±', 'ğŸ‘·', 'â˜˜', 'ğŸ˜³', 'ã‚œ', 'ì¥”', 'ğŸ”Š', 'í‹´', 'âœ‰', 'å¸Œ', '\\n', 'ğŸ', 'ï¼', 'Ù…', 'ë‹¤', 'ğŸŒ¤', 'ğŸ‡°', 'ğŸ˜™', 'Ë¢', 'à¸ª', 'ğŸ˜„', 'ğŸ”„', 'â•”', 'ğŸ†•', 'æœˆ', 'í', 'ğŸ’š', 'ğŸ’‹', 'ê·¼', 'ì›Œ', 'ğŸ¤¤', 'â—€', 'ğŸ™ƒ', 'ğŸ’', 'Ã‚', 'ìˆ˜', 'ğŸ”¼', 'ï¼¢', 'â†ª', 'ğŸ–•', 'à¹', 'ğŸ—¼', 'ğŸ’›', 'ğŸŒ', \"'\", 'ğŸ˜—', 'ã€¡', 'â˜', 'å—', 'ğŸ‡®', 'ğŸ¥‡', 'â€¹', 'à¹ˆ', '3', 'å°”', 'â”', 'ğŸ”±', 'ğŸ–', 'ã€', 'ç”Ÿ', 'å˜‰', 'ğŸŠ', 'áµ‡', 'ğŸ‘€', 'ğŸ›', 'Â¿', 'f', 'ë§', 'ï¸', 'p', 'â›½', 'ìš¸', 'ï¿£', 'ğŸ»', 'à¼½', 'â…', 'Ñ', 's', 'â•®', 'ì„±', 'â–²', 'ğŸ˜', 'à¸', 'ãƒ•', 'ğŸ‡¹', 'â›·', 'ğŸ—¨', 'ğŸ˜', 'ç”¨', 'âš°', 'æ¯…', 'ğŸ˜º', 'ì„œ', 'ØŒ', 'ğŸ˜ª', 'ğŸ†', 'ğŸ’Š', 'Ğ˜', 'ğŸ™', 'ğŸ‘½', 'åŠª', 'Ø¯', 'ğŸŒ›']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2\n",
        "Implement the function *lm* that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant *n*-1 sequences, and the values are dictionaries with the *n*_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
        "\n",
        "{ \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25}, \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1} }\n",
        "\n",
        "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
        "\n",
        "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
      ],
      "metadata": {
        "id": "tpjtwHW08jyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_unigram_model(tweet_texts, smoothed, vocabulary):\n",
        "    model = {'×': len(tweet_texts), '×ª': len(tweet_texts)}\n",
        "    total_characters = sum((len(tweet)+2) for tweet in tweet_texts)\n",
        "\n",
        "    for tweet in tweet_texts:\n",
        "      for char in tweet:\n",
        "        if char in model:\n",
        "            model[char] += 1\n",
        "        else:\n",
        "            model[char] = 1\n",
        "\n",
        "    for char in model:\n",
        "        model[char] = model[char] / total_characters\n",
        "\n",
        "    if smoothed:\n",
        "        model['<unk>'] = 1 / len(vocabulary)\n",
        "    return model\n",
        "\n",
        "def add_n_gram(model, counts, n_gram, suffix):\n",
        "  if n_gram in model.keys():\n",
        "    if suffix in model[n_gram]:\n",
        "      model[n_gram][suffix] += 1\n",
        "    else:\n",
        "      model[n_gram][suffix] = 1\n",
        "    counts[n_gram] += 1\n",
        "  else:\n",
        "    model[n_gram] = {suffix: 1}\n",
        "    counts[n_gram] = 1\n",
        "\n",
        "def lm(lang: str, n: int, smoothed: bool = False) -> dict[str, dict[str, float]]:\n",
        "  '''\n",
        "  Return a language model for the given lang and n_gram (n)\n",
        "  :param lang: the language of the model\n",
        "  :param n: the n_gram value\n",
        "  :return: a dictionary where the keys are n_grams and the values are dictionaries\n",
        "  '''\n",
        "  model = {}\n",
        "  counts = {}\n",
        "  vocabulary = preprocess()\n",
        "\n",
        "  file_path = os.path.join('/content/data', f'{lang}.json')\n",
        "  tweet_texts = get_tweet_texts(file_path)\n",
        "\n",
        "  if n == 1:\n",
        "    return create_unigram_model(tweet_texts, smoothed, vocabulary)\n",
        "\n",
        "  for tweet in tweet_texts:\n",
        "    tweet = \"×\" * (n-1) + tweet + \"×ª\"\n",
        "    for i in range(len(tweet)-n+1):\n",
        "        n_gram = tweet[i:i+n-1]\n",
        "        suffix = tweet[i+n-1]\n",
        "        add_n_gram(model, counts, n_gram, suffix)\n",
        "\n",
        "  for n_gram, followers in model.items():\n",
        "    for suffix in followers:\n",
        "      if smoothed:\n",
        "        model[n_gram][suffix] = (model[n_gram][suffix] + 1) / (counts[n_gram] + len(vocabulary))\n",
        "      else:\n",
        "        model[n_gram][suffix] = model[n_gram][suffix] / counts[n_gram]\n",
        "\n",
        "  if smoothed:\n",
        "    model['<unk>'] = 1 / len(vocabulary)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "print(lm('en', 1, True))"
      ],
      "metadata": {
        "id": "uySEXdEUrkq_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d3c7c92-40ab-4333-f0b3-9a781972dad4"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'×': 0.010404015869160392, '×ª': 0.010404015869160392, 'R': 0.009852296517343881, 'T': 0.012585447100870954, ' ': 0.13628277640908198, '@': 0.009886995847646808, 'O': 0.00480007402523798, 'N': 0.003984639763119239, 'H': 0.0037683472708976715, 'E': 0.004626577373723354, 'P': 0.0035520547786761047, 'l': 0.027951467203349643, 'D': 0.003939530633725436, ':': 0.012956729935112252, 'B': 0.003858565529685277, 'o': 0.05263078755913344, 'y': 0.015909642943891182, 'f': 0.011044796835421077, 'r': 0.03567438148443735, 'i': 0.04097181257735059, 'e': 0.06718137339949339, 'n': 0.03939761962594122, 'd': 0.019728882565899813, 's': 0.04193876724845877, 't': 0.0636038724452618, 'h': 0.03140173727980383, 'a': 0.04990342019732352, 'k': 0.008338249071792914, 'p': 0.01844385070034815, 'c': 0.022158992331448003, 'u': 0.01918988630186104, 'g': 0.013568594792787166, 'w': 0.011410296447945221, 'm': 0.016614039349040564, 'ğŸ˜': 2.3132886868616768e-05, 'â˜º': 1.619302080803174e-05, 'ï¸': 0.0003666562568675758, 'b': 0.009802560810576356, \"'\": 0.00344911343211076, '/': 0.018500526273176263, '.': 0.013265553974808286, '5': 0.0018309679956510173, 'M': 0.004949281145540558, 'A': 0.005866500109881213, '8': 0.0013486473044403576, '1': 0.002893924147263958, 'F': 0.0033519553072625698, 'v': 0.007238280301190187, '_': 0.001576506240096233, '9': 0.001481661403934904, '2': 0.0024312664098916224, 'I': 0.006385833420081659, 'C': 0.004885665706651862, 'U': 0.0022809026452456135, 'Y': 0.002500665070497473, '#': 0.004132690239078386, '0': 0.002541147622517552, '7': 0.0016077356373688655, 'L': 0.004078327954937136, 'V': 0.0017777623558531987, 'S': 0.0070751934487664385, 'X': 0.001201753472824641, '6': 0.0014770348265611807, 'K': 0.002277432712215321, ',': 0.002651028835143482, 'G': 0.003229351006858901, 'W': 0.0036700325017060506, '3': 0.001768509201105752, '&': 0.0005308997536347548, '!': 0.0024231698994876066, 'Q': 0.0011485478330268226, 'J': 0.0020553569982765998, 'â€™': 0.00021166591484784344, '-': 0.0012179464936326728, 'Z': 0.0011231016574713441, 'z': 0.0020646101530240467, '$': 0.0001052546352522063, 'ğŸ˜¥': 2.313288686861677e-06, 'ğŸ‘€': 2.8916108585770962e-05, 'ğŸ™': 3.816926333321767e-05, 'q': 0.0012942850202991082, '4': 0.0017766057115097679, '~': 3.122939727263264e-05, 'j': 0.0023352649293868627, 'ğŸ€': 2.313288686861677e-06, 'ğŸ‘Š': 8.09651040401587e-06, 'x': 0.0024983517818106113, '\"': 0.0012422360248447205, 'ğŸ¤¦': 2.3132886868616768e-05, 'ğŸ½': 6.939866060585031e-05, '\\u200d': 4.973570676752605e-05, 'â™‚': 1.50363764646009e-05, 'ğŸ˜‚': 0.00040713880888765513, 'â€¦': 0.0019882716263576114, '(': 0.0003469933030292515, ')': 0.0003759094116150225, 'ğŸŒ¹': 9.253154747446708e-06, '?': 0.0011265715905016366, 'ğŸ’¥': 1.9662953838324255e-05, 'ğŸ’¯': 3.122939727263264e-05, 'âœ”': 1.619302080803174e-05, '>': 0.00010178470222191378, 'â­': 4.626577373723354e-06, 'â¡': 1.619302080803174e-05, 'â¬…': 2.313288686861677e-06, '[': 8.096510404015869e-05, ']': 7.749517100986618e-05, 'â€¼': 9.253154747446708e-06, 'ï¼ ': 9.253154747446708e-06, 'ğŸ˜˜': 2.197624252518593e-05, '*': 0.00020588269313068924, 'ğŸ™€': 1.1566443434308385e-06, '%': 0.00010872456828249882, 'ğŸ‘': 2.6602819898909284e-05, 'ğŸ¤—': 1.50363764646009e-05, 'ğŸ˜›': 8.09651040401587e-06, 'ğŸ™Œ': 3.932590767664851e-05, 'ğŸ˜': 3.00727529292018e-05, 'ğŸ˜†': 1.0409799090877545e-05, 'ğŸ»': 5.089235111095689e-05, 'âœ¨': 6.824201626241947e-05, 'â™¥': 1.7349665151462578e-05, 'â™¡': 5.783221717154192e-06, 'â€œ': 0.00010641127959563714, 'ğŸ˜': 0.00016771342979747156, 'ğŸ¤£': 3.00727529292018e-05, 'ğŸ˜¤': 1.3879732121170062e-05, 'ğŸ¼': 6.130215020183444e-05, 'â€¢': 2.4289531212047607e-05, 'ğŸ“²': 5.783221717154192e-06, 'ğŸ‘‰': 1.8506309494893417e-05, 'ğŸ¤': 1.3879732121170062e-05, 'ğŸ§': 1.3879732121170062e-05, 'ğŸ‡³': 9.253154747446708e-06, 'ğŸ‡¬': 9.253154747446708e-06, 'ğŸ‘‡': 4.626577373723354e-06, 'ã…¤': 0.0002313288686861677, 'ğŸŒ´': 1.1566443434308384e-05, 'ğŸ–¤': 5.783221717154192e-06, 'ğŸ¤³': 1.1566443434308385e-06, 'ğŸŒŠ': 3.4699330302925154e-06, 'â˜€': 1.0409799090877545e-05, 'â€': 9.253154747446707e-05, 'â¤': 0.000150363764646009, '+': 8.096510404015869e-05, 'ğŸ˜„': 9.253154747446708e-06, 'â†˜': 1.1566443434308385e-06, 'â†—': 1.1566443434308385e-06, 'ğŸ˜': 2.313288686861677e-06, 'ğŸ“¦': 1.1566443434308385e-06, '|': 0.00010409799090877546, 'ğŸ‡±': 4.626577373723354e-06, 'ğŸ¼': 6.939866060585031e-06, 'ğŸ¶': 2.6602819898909284e-05, 'ğŸ’': 5.783221717154192e-06, 'ğŸ‘ˆ': 8.09651040401587e-06, 'ğŸ’…': 2.313288686861677e-06, 'â €': 2.313288686861677e-06, 'ğŸ”¥': 0.00010988121262592965, 'ğŸ˜«': 8.09651040401587e-06, 'ğŸ˜': 2.081959818175509e-05, 'ğŸ’¿': 3.4699330302925154e-06, ';': 8.559168141388204e-05, 'ğŸ’™': 3.354268595949432e-05, 'â€”': 4.163919636351018e-05, 'â„ƒ': 1.1566443434308385e-06, 'â‡˜': 1.1566443434308385e-06, 'Â´': 4.626577373723354e-06, '^': 1.8506309494893417e-05, 'âš½': 1.0409799090877545e-05, 'ğŸ‡¿': 1.1566443434308385e-06, 'ğŸ“': 1.0409799090877545e-05, 'Ã©': 1.2723087777739223e-05, 'Ğ': 1.1566443434308385e-06, 'Ñ€': 2.313288686861677e-06, 'Ñ…': 1.1566443434308385e-06, 'Ğ¸': 1.1566443434308385e-06, 'Ñ‚': 2.313288686861677e-06, 'Ğµ': 1.1566443434308385e-06, 'Ğº': 1.1566443434308385e-06, 'Ñƒ': 1.1566443434308385e-06, 'Ğ°': 1.1566443434308385e-06, 'ğŸ˜­': 0.00015730363070659404, 'ğŸ’ª': 3.816926333321767e-05, 'ğŸ¦': 3.4699330302925154e-06, 'ğŸ™': 2.313288686861677e-06, 'ï¿¼': 2.313288686861677e-06, 'ğŸ‡®': 1.1566443434308384e-05, 'ğŸ‡¹': 6.939866060585031e-06, 'ğŸ‡¦': 3.4699330302925154e-06, 'Â£': 2.5446175555478446e-05, 'ğŸ™': 5.783221717154192e-06, '\\u200b': 5.783221717154192e-06, 'ğŸ´': 2.313288686861677e-06, 'ğŸ˜´': 1.3879732121170062e-05, 'ğŸ†“': 6.939866060585031e-06, 'â“': 4.626577373723354e-06, 'ğŸ±': 6.939866060585031e-06, 'ğŸ£': 6.939866060585031e-06, 'ğŸ‘¶': 9.253154747446708e-06, 'ğŸ¾': 1.2723087777739223e-05, 'ğŸ™ˆ': 9.253154747446708e-06, 'ğŸ·': 9.253154747446708e-06, 'ğŸ£': 8.09651040401587e-06, 'ğŸ”': 6.939866060585031e-06, 'ğŸ‘¹': 6.939866060585031e-06, 'ğŸ‘¿': 8.09651040401587e-06, 'ğŸ”«': 8.09651040401587e-06, 'ğŸ’£': 8.09651040401587e-06, 'â˜ ': 9.253154747446708e-06, 'ğŸ˜·': 1.50363764646009e-05, 'ğŸ”ª': 2.3132886868616768e-05, 'ğŸ’š': 5.783221717154192e-06, 'ğŸ”': 2.313288686861677e-06, 'ğŸ¤˜': 8.09651040401587e-06, 'ğŸŒš': 4.626577373723354e-06, 'ï¿½': 4.626577373723354e-06, 'ğŸ’ƒ': 5.783221717154192e-06, 'â€“': 2.081959818175509e-05, 'ğŸ‡º': 9.253154747446708e-06, 'ğŸ‡¸': 9.253154747446708e-06, 'ğŸ˜Œ': 1.0409799090877545e-05, 'Î©': 1.1566443434308385e-06, 'ğŸº': 8.09651040401587e-06, 'ğŸ’«': 1.1566443434308384e-05, 'ğŸ‘‘': 9.253154747446708e-06, '\\\\': 3.4699330302925154e-06, 'ã… ': 4.626577373723354e-06, 'ğŸ‘': 4.8579062424095214e-05, 'ğŸ': 1.1566443434308385e-06, 'ğŸ‰': 1.619302080803174e-05, '{': 3.4699330302925154e-06, '}': 3.4699330302925154e-06, 'ğŸ“': 1.1566443434308385e-06, 'ğŸŒº': 3.4699330302925154e-06, 'ğŸŒ¸': 1.3879732121170062e-05, 'â„¢': 1.3879732121170062e-05, 'ï¼²': 5.783221717154192e-06, 'ï¼¥': 1.0409799090877545e-05, 'ï¼´': 6.939866060585031e-06, 'ï¼·': 1.2723087777739223e-05, 'ï¼¯': 1.50363764646009e-05, 'ï¼®': 6.939866060585031e-06, 'ï¼¬': 1.2723087777739223e-05, 'ï¼¹': 3.4699330302925154e-06, 'ï¼©': 4.626577373723354e-06, 'ï¼¦': 8.09651040401587e-06, 'ï¼µ': 2.313288686861677e-06, 'ã€¡': 1.7349665151462578e-05, 'ï¼¢': 2.313288686861677e-06, 'ï¼¡': 5.783221717154192e-06, 'ï¼£': 2.313288686861677e-06, 'ï¼«': 2.313288686861677e-06, 'ğŸŒ': 2.313288686861677e-06, 'ğŸŒ': 3.4699330302925154e-06, 'ğŸ’“': 1.50363764646009e-05, 'âœŒ': 1.619302080803174e-05, 'ğŸ—½': 1.1566443434308385e-06, 'Ã¸': 1.1566443434308385e-06, 'ğŸ˜©': 3.122939727263264e-05, 'ğŸ˜': 9.253154747446708e-06, 'ğŸ’€': 2.8916108585770962e-05, 'â˜¹': 5.783221717154192e-06, 'â†º': 9.253154747446708e-06, 'ğŸ˜»': 3.4699330302925154e-06, 'ğŸ’–': 1.8506309494893417e-05, 'ğŸ’•': 3.122939727263264e-05, 'ğŸ‘°': 3.4699330302925154e-06, 'ğŸ¾': 5.5518928484680246e-05, 'Â¿': 5.783221717154192e-06, 'âƒ£': 1.3879732121170062e-05, 'ğŸ¤”': 3.4699330302925156e-05, 'ğŸƒ': 5.783221717154192e-06, 'ğŸ‘Œ': 2.4289531212047607e-05, 'â€˜': 2.8916108585770962e-05, 'ğŸ˜…': 9.253154747446708e-06, 'ğŸ˜‡': 1.3879732121170062e-05, 'ğŸ‘ ': 3.4699330302925154e-06, 'ğŸ˜Š': 2.5446175555478446e-05, 'ğŸ’‹': 1.2723087777739223e-05, 'ğŸ™‹': 1.1566443434308385e-06, 'ğŸ˜š': 1.1566443434308385e-06, 'ğŸŠ': 2.313288686861677e-06, 'Â®': 1.1566443434308385e-06, 'ğŸ¤·': 2.5446175555478446e-05, '=': 2.6602819898909284e-05, 'âœ‰': 2.313288686861677e-06, 'ğŸŸ': 2.313288686861677e-06, 'ğŸ’—': 1.2723087777739223e-05, 'â„': 6.939866060585031e-06, 'ğŸ‘¨': 2.313288686861677e-06, 'âš•': 1.1566443434308385e-06, 'ğŸ': 6.939866060585031e-06, '<': 2.7759464242340123e-05, 'ğŸ¤¤': 3.4699330302925154e-06, 'ğŸ™„': 2.5446175555478446e-05, 'ğŸ¤“': 4.626577373723354e-06, 'ğŸ¦„': 3.4699330302925154e-06, 'ğŸŒˆ': 5.783221717154192e-06, 'â†’': 1.1566443434308385e-06, 'ğŸ‡ª': 6.939866060585031e-06, 'ğŸ‡²': 1.1566443434308385e-06, 'ğŸ‡©': 2.313288686861677e-06, 'ğŸ”´': 8.09651040401587e-06, 'ğŸ‘': 4.626577373723354e-06, 'ğŸ¥‡': 2.313288686861677e-06, 'ğŸ†': 3.4699330302925154e-06, 'â™€': 3.5855974646355994e-05, 'ğŸ˜•': 3.4699330302925154e-06, 'ğŸ˜¬': 3.4699330302925154e-06, 'ğŸ˜€': 8.09651040401587e-06, 'â›ª': 1.1566443434308385e-06, 'ğŸš˜': 2.313288686861677e-06, 'ğŸ˜–': 2.313288686861677e-06, 'ğŸŒ': 2.313288686861677e-06, 'ğŸ˜®': 3.4699330302925154e-06, 'ğŸ˜‘': 6.939866060585031e-06, 'ğŸ™ƒ': 1.0409799090877545e-05, 'â‰': 2.313288686861677e-06, 'ğŸ˜±': 1.3879732121170062e-05, 'ğŸ˜”': 1.2723087777739223e-05, 'ØŒ': 1.1566443434308385e-06, 'ğŸ“¢': 3.4699330302925154e-06, 'ğŸš¨': 1.9662953838324255e-05, 'á´°': 3.4699330302925154e-06, 'áµƒ': 1.619302080803174e-05, 'áµ‡': 4.626577373723354e-06, 'áµ—': 4.626577373723354e-06, 'Ê¸': 4.626577373723354e-06, 'áµ’': 3.4699330302925154e-06, 'áµ˜': 2.313288686861677e-06, 'Ê³': 6.939866060585031e-06, 'Ë¢': 2.313288686861677e-06, 'áµ‰': 5.783221717154192e-06, 'áµ›': 1.1566443434308385e-06, 'â±': 2.313288686861677e-06, 'á¶œ': 1.1566443434308385e-06, 'Ë¡': 1.1566443434308385e-06, 'Ê·': 2.313288686861677e-06, 'áµˆ': 3.4699330302925154e-06, 'á¶ ': 2.313288686861677e-06, 'Ê°': 3.4699330302925154e-06, 'â·': 1.1566443434308385e-06, 'ğŸ¤¢': 2.313288686861677e-06, 'ğŸš–': 1.1566443434308385e-06, 'ğŸ“·': 1.0409799090877545e-05, 'â˜›': 1.1566443434308385e-06, 'â˜š': 1.1566443434308385e-06, 'ğŸ’”': 1.0409799090877545e-05, 'ğŸ€': 3.4699330302925154e-06, 'â™£': 4.626577373723354e-06, 'ğŸ”±': 4.626577373723354e-06, 'â“¦': 2.313288686861677e-06, 'â“˜': 2.313288686861677e-06, 'â“¢': 4.626577373723354e-06, 'ğŸ˜°': 1.1566443434308385e-06, 'ğŸ–•': 0.00010988121262592965, 'ã€Œ': 1.1566443434308385e-06, 'ã€': 1.1566443434308385e-06, 'ì ¤': 2.313288686861677e-06, 'ë¡œ': 2.313288686861677e-06, 'ğŸŒ': 5.783221717154192e-06, 'ğŸ‘™': 1.1566443434308385e-06, 'Â»': 8.09651040401587e-06, 'Â«': 1.1566443434308385e-06, 'ğŸ”œ': 2.313288686861677e-06, 'Ø­': 2.313288686861677e-06, 'ÙŠ': 3.4699330302925154e-06, 'Ø§': 8.09651040401587e-06, 'Øª': 2.313288686861677e-06, 'Ùƒ': 2.313288686861677e-06, 'Ù„': 3.4699330302925154e-06, 'Ùˆ': 3.4699330302925154e-06, 'Ù‡': 2.313288686861677e-06, 'Ù…': 5.783221717154192e-06, 'Ù†': 1.1566443434308385e-06, 'Øº': 1.1566443434308385e-06, 'Ø±': 8.09651040401587e-06, 'ğŸ™†': 1.1566443434308385e-06, 'ğŸŒ§': 2.313288686861677e-06, 'ğŸ˜’': 9.253154747446708e-06, 'ğŸ™‚': 6.939866060585031e-06, 'â': 4.626577373723354e-06, 'â': 4.626577373723354e-06, 'ğŸ’°': 5.783221717154192e-06, 'ğŸ¾': 1.1566443434308385e-06, 'âœŠ': 9.253154747446708e-06, 'ğŸ¿': 2.313288686861677e-06, 'ğŸ™': 2.313288686861677e-06, 'ğŸ—£': 1.3879732121170062e-05, 'ğŸ’œ': 1.2723087777739223e-05, 'ğŸŒ…': 1.1566443434308385e-06, 'ğŸ–': 1.1566443434308385e-06, 'ğŸš': 1.1566443434308385e-06, 'ğŸ„': 1.1566443434308385e-06, '\\U000fe4e6': 3.4699330302925154e-06, 'â¤': 2.313288686861677e-06, '\\x91': 1.1566443434308385e-06, '\\x92': 2.313288686861677e-06, 'ğŸˆ': 2.313288686861677e-06, 'ğŸ¤™': 2.313288686861677e-06, 'ğŸ˜‹': 8.09651040401587e-06, 'í‹´': 3.4699330302925154e-06, 'íƒ‘': 2.313288686861677e-06, 'í•˜': 2.313288686861677e-06, 'ì´': 4.626577373723354e-06, 'íŒŒ': 2.313288686861677e-06, 'ë¸Œ': 2.313288686861677e-06, 'ë¦¬': 3.4699330302925154e-06, 'í‚¤': 2.313288686861677e-06, 'ğŸ˜‰': 1.2723087777739223e-05, 'ğŸ˜ª': 8.09651040401587e-06, 'Ø·': 4.626577373723354e-06, 'Ø¯': 2.313288686861677e-06, 'Ø¬': 1.1566443434308385e-06, 'Ø¹': 1.1566443434308385e-06, 'Ù‚': 1.1566443434308385e-06, 'ğŸŠ': 9.253154747446708e-06, 'ğŸ¥‚': 5.783221717154192e-06, 'ğŸ’›': 5.783221717154192e-06, 'âš«': 1.1566443434308385e-06, 'ğŸ”µ': 2.313288686861677e-06, 'ğŸ˜¨': 2.313288686861677e-06, 'ğŸ˜œ': 9.253154747446708e-06, 'ğŸ˜¢': 4.626577373723354e-06, 'ğŸˆ': 1.1566443434308385e-06, 'ã€°': 3.4699330302925154e-06, 'â¬‡': 2.313288686861677e-06, 'ğŸ˜¡': 4.626577373723354e-06, 'â¦‘': 1.1566443434308385e-06, 'â¦’': 1.1566443434308385e-06, 'â‹': 1.1566443434308385e-06, 'â¸„': 1.1566443434308385e-06, 'â¸…': 1.1566443434308385e-06, 'ğŸ’¨': 4.626577373723354e-06, 'ğŸ‘…': 5.783221717154192e-06, 'ğŸ': 2.313288686861677e-06, 'ğŸ¡': 1.1566443434308385e-06, 'ğŸ¦€': 2.313288686861677e-06, 'ğŸ¦‘': 2.313288686861677e-06, 'ğŸ˜£': 1.1566443434308385e-06, 'ğŸ»': 4.626577373723354e-06, 'â™': 1.1566443434308385e-06, 'åˆ': 1.1566443434308385e-06, 'å¾Œ': 1.1566443434308385e-06, 'ï¼˜': 1.1566443434308385e-06, 'æ™‚': 1.1566443434308385e-06, 'ï¼“': 1.1566443434308385e-06, 'åˆ†': 1.1566443434308385e-06, 'ì§„': 2.313288686861677e-06, 'ì„': 1.1566443434308385e-06, 'ì°Œ': 1.1566443434308385e-06, 'ë‹ˆ': 1.1566443434308385e-06, 'ë°©': 5.783221717154192e-06, 'íƒ„': 5.783221717154192e-06, 'ì†Œ': 4.626577373723354e-06, 'ë…„': 4.626577373723354e-06, 'ë‹¨': 4.626577373723354e-06, 'â˜': 1.1566443434308385e-06, 'ğŸŒ·': 5.783221717154192e-06, 'ğŸ’': 1.0409799090877545e-05, 'ğŸ˜ˆ': 1.8506309494893417e-05, 'Â©': 4.626577373723354e-06, 'ğŸ¿': 1.1566443434308385e-06, 'ğŸ': 4.626577373723354e-06, 'ğŸ‘²': 1.1566443434308385e-06, 'ğŸ’Ÿ': 3.4699330302925154e-06, 'ğŸ‘“': 1.1566443434308385e-06, 'ğŸŒŸ': 1.0409799090877545e-05, 'ğŸŒ™': 3.4699330302925154e-06, 'ğŸ“°': 2.313288686861677e-06, 'ğŸ’„': 1.1566443434308385e-06, 'ğŸŒ¥': 1.1566443434308385e-06, 'ğŸ“¸': 1.1566443434308385e-06, 'âš¡': 4.8579062424095214e-05, 'âŠ': 4.626577373723354e-06, 'â‹': 4.626577373723354e-06, 'âŒ': 4.626577373723354e-06, 'â': 4.626577373723354e-06, 'â': 3.4699330302925154e-06, 'â': 3.4699330302925154e-06, 'â˜': 4.626577373723354e-06, 'ğŸ¤‘': 2.313288686861677e-06, 'ğŸ’µ': 4.626577373723354e-06, 'ğŸ’¸': 4.626577373723354e-06, 'â€•': 4.626577373723354e-06, '\\n': 2.313288686861677e-06, 'Å': 1.1566443434308385e-06, 'ğŸ²': 1.1566443434308385e-06, 'ğŸ¦‰': 1.1566443434308385e-06, 'ğŸ¤•': 1.1566443434308385e-06, 'ğŸ¤’': 1.1566443434308385e-06, 'ğŸ˜“': 3.4699330302925154e-06, 'ğŸ¨': 2.313288686861677e-06, 'ğŸ•': 1.1566443434308385e-06, 'ğŸŒ»': 2.313288686861677e-06, 'ğŸ…±': 1.1566443434308385e-06, 'ğŸŠ': 1.1566443434308385e-06, 'â˜˜': 5.783221717154192e-06, 'ğŸ˜': 4.626577373723354e-06, 'ì •': 3.4699330302925154e-06, 'êµ­': 1.1566443434308385e-06, 'â˜„': 1.1566443434308385e-06, 'ğŸŒ‹': 1.1566443434308385e-06, 'â£': 5.783221717154192e-06, 'ğŸ¶': 4.626577373723354e-06, 'ì§€': 2.313288686861677e-06, 'ë¯¼': 1.1566443434308385e-06, 'ğŸ¯': 1.1566443434308385e-06, 'ğŸ„': 1.1566443434308385e-06, 'ğŸ–': 1.1566443434308385e-06, 'ğŸ“': 1.1566443434308385e-06, 'ğŸ†': 2.313288686861677e-06, 'ğŸ’¦': 8.09651040401587e-06, 'ğŸ‘„': 2.313288686861677e-06, 'ğŸ”': 2.313288686861677e-06, 'ğŸ“¹': 1.1566443434308385e-06, 'Ã§': 1.1566443434308385e-06, 'âˆ†': 1.1566443434308385e-06, 'ğŸ’†': 2.313288686861677e-06, 'ğŸ—³': 1.1566443434308385e-06, 'ğŸ½': 1.1566443434308385e-06, 'ãƒ»': 6.939866060585031e-06, 'ğŸ˜': 3.4699330302925154e-06, 'â›³': 1.1566443434308385e-06, 'â—': 1.7349665151462578e-05, 'ğŸ’': 3.4699330302925154e-06, 'ğŸ»': 1.1566443434308385e-06, 'ğŸ¼': 1.1566443434308385e-06, 'ğŸ‘': 2.313288686861677e-06, 'í”„': 1.1566443434308385e-06, 'ìŠ¤': 5.783221717154192e-06, 'ğŸ’': 3.4699330302925154e-06, 'ğŸ©': 1.1566443434308385e-06, 'ğŸ’': 9.253154747446708e-06, 'ìœ ': 1.1566443434308385e-06, 'ì—°': 2.313288686861677e-06, 'ğŸ˜½': 5.783221717154192e-06, 'ì•„': 3.4699330302925154e-06, 'ë¦„': 3.4699330302925154e-06, 'ë‹¤': 3.4699330302925154e-06, 'ì›Œ': 3.4699330302925154e-06, 'ğŸ¾': 2.313288686861677e-06, 'Â¡': 6.939866060585031e-06, 'ğŸ‹': 1.1566443434308385e-06, 'ğŸ’ˆ': 2.313288686861677e-06, 'âš ': 1.619302080803174e-05, 'ğŸŒ¾': 3.4699330302925154e-06, 'ğŸŒ¼': 3.4699330302925154e-06, 'ğŸ‘†': 1.1566443434308385e-06, 'ì„¸': 1.1566443434308385e-06, 'í›ˆ': 1.1566443434308385e-06, 'ğŸŠ': 1.1566443434308385e-06, 'ğŸ˜³': 1.3879732121170062e-05, 'ï¼§': 3.4699330302925154e-06, 'ğŸ': 3.4699330302925154e-06, 'ğŸ‡§': 3.4699330302925154e-06, 'Â¯': 4.626577373723354e-06, 'ãƒ„': 2.313288686861677e-06, 'ğŸ‡µ': 2.313288686861677e-06, 'ğŸ˜¯': 1.1566443434308385e-06, 'ğŸº': 2.313288686861677e-06, 'ğŸ‹': 1.1566443434308385e-06, 'ğŸ‡': 4.626577373723354e-06, 'Ã¯': 2.313288686861677e-06, 'ğŸ™‡': 2.313288686861677e-06, 'ğŸŒ³': 1.1566443434308385e-06, 'â†ª': 1.1566443434308385e-06, 'ğŸ™…': 3.4699330302925154e-06, 'ğŸ‘': 2.313288686861677e-06, 'ğŸ¥˜': 1.1566443434308385e-06, 'ğŸ®': 1.1566443434308385e-06, 'âœˆ': 1.1566443434308385e-06, 'ğŸ”¹': 1.1566443434308385e-06, 'ğŸ’½': 1.1566443434308385e-06, 'Í¡': 2.313288686861677e-06, 'Â°': 1.2723087777739223e-05, 'Íœ': 1.1566443434308385e-06, 'Ê–': 1.1566443434308385e-06, 'ğŸ¼': 1.1566443434308385e-06, 'ë ˆ': 1.1566443434308385e-06, 'ë“œ': 1.1566443434308385e-06, 'ë²¨': 1.1566443434308385e-06, 'ë²³': 1.1566443434308385e-06, 'âœ…': 5.783221717154192e-06, 'ğŸ“š': 3.4699330302925154e-06, 'âœ§': 1.1566443434308385e-06, 'â˜•': 1.1566443434308385e-06, 'ğŸ†˜': 2.313288686861677e-06, 'ğŸ”¶': 2.313288686861677e-06, 'â©': 1.1566443434308385e-06, 'ğŸŒ°': 1.1566443434308385e-06, 'ğŸ‘»': 2.313288686861677e-06, 'ğŸ¤§': 2.313288686861677e-06, 'Ã¡': 1.1566443434308385e-06, 'ğŸ’Œ': 1.1566443434308385e-06, 'ğŸ‘‹': 4.626577373723354e-06, 'ğŸ‡´': 1.1566443434308385e-06, 'Ã¼': 3.4699330302925154e-06, 'âŒ': 4.626577373723354e-06, 'ğŸ“º': 3.4699330302925154e-06, '`': 2.313288686861677e-06, 'ğŸ¤š': 1.1566443434308385e-06, 'ğŸ‘¤': 1.1566443434308385e-06, 'ì¹´': 1.1566443434308385e-06, 'ë…¸': 1.1566443434308385e-06, 'ê²Œ': 1.1566443434308385e-06, 'ì„': 1.1566443434308385e-06, '\\u3000': 2.313288686861677e-06, 'â™¯': 1.1566443434308385e-06, 'ğŸ¯': 1.1566443434308385e-06, 'Ã–': 1.1566443434308385e-06, 'â”': 3.4699330302925154e-06, 'â”“': 3.4699330302925154e-06, 'â”ƒ': 3.4699330302925154e-06, 'â•±': 8.09651040401587e-06, 'â•²': 6.939866060585031e-06, 'â•­': 2.313288686861677e-06, 'â•®': 2.313288686861677e-06, 'â–”': 1.3879732121170062e-05, 'â–': 1.1566443434308385e-06, 'â”—': 1.1566443434308385e-06, 'â”›': 1.1566443434308385e-06, 'â–•': 1.1566443434308385e-06, 'â”³': 2.313288686861677e-06, 'ğŸ¤': 1.1566443434308385e-06, 'ğŸ’': 2.313288686861677e-06, 'ğŸ“ˆ': 1.1566443434308385e-06, 'ğŸ—': 2.313288686861677e-06, 'â˜‘': 1.1566443434308385e-06, 'ğŸ‘¯': 1.1566443434308385e-06, 'ğŸ‡°': 1.1566443434308385e-06, 'ğŸ“…': 1.1566443434308385e-06, 'ğŸƒ': 1.1566443434308385e-06, 'ğŸ³': 1.1566443434308385e-06, 'âš”': 1.1566443434308385e-06, 'âšª': 3.4699330302925154e-06, 'ã€‹': 4.626577373723354e-06, 'Ã­': 1.1566443434308385e-06, 'ğŸ‘': 1.1566443434308385e-06, 'ğŸ’‰': 3.4699330302925154e-06, 'ğŸ”': 3.4699330302925154e-06, 'ğŸ˜ƒ': 4.626577373723354e-06, 'ğŸš£': 1.1566443434308385e-06, 'Ã«': 1.1566443434308385e-06, 'ğŸ‚': 1.1566443434308385e-06, 'ğŸ‘­': 1.1566443434308385e-06, 'âœ': 1.1566443434308385e-06, 'ğŸ’­': 1.1566443434308385e-06, 'ë“€': 1.1566443434308385e-06, 'ì—£': 1.1566443434308385e-06, 'ê°€': 1.1566443434308385e-06, 'ìš”': 1.1566443434308385e-06, 'ì œ': 1.1566443434308385e-06, 'ğŸ‘¦': 1.1566443434308385e-06, 'ğŸ‘§': 1.1566443434308385e-06, 'ğŸ’‘': 1.1566443434308385e-06, 'ğŸ‘ª': 2.313288686861677e-06, 'ğŸ‘«': 2.313288686861677e-06, 'ğŸ¡': 1.1566443434308385e-06, 'ğŸ ': 1.1566443434308385e-06, 'ğŸ¢': 1.1566443434308385e-06, 'ğŸª': 1.1566443434308385e-06, 'â›“': 2.313288686861677e-06, 'ëª¬': 2.313288686861677e-06, 'íƒ€': 2.313288686861677e-06, 'ì—‘': 2.313288686861677e-06, 'ì…”': 1.1566443434308385e-06, 'ëˆ„': 1.1566443434308385e-06, 'á´¬': 1.1566443434308385e-06, 'á¶°': 2.313288686861677e-06, 'â™': 1.1566443434308385e-06, 'âš': 6.939866060585031e-06, 'ğŸ”…': 4.626577373723354e-06, 'â˜™': 5.783221717154192e-06, 'â˜°': 3.4699330302925154e-06, 'ğŸ”': 1.1566443434308385e-06, 'â•‘': 4.6265773737233536e-05, 'âŒš': 1.1566443434308385e-06, 'âœ¡': 1.1566443434308385e-06, 'ğŸ•': 1.1566443434308385e-06, 'ğŸ‡¨': 1.1566443434308385e-06, 'ğŸ”©': 1.1566443434308385e-06, 'â‚¬': 1.1566443434308385e-06, 'ğŸ’˜': 1.1566443434308385e-06, 'ì£¼': 1.1566443434308385e-06, 'í—Œ': 1.1566443434308385e-06, 'âœ‹': 1.1566443434308385e-06, 'ğŸ˜²': 1.1566443434308385e-06, 'í˜¸': 1.1566443434308385e-06, 'ì•¼': 1.1566443434308385e-06, 'ğŸ’': 2.313288686861677e-06, 'â–º': 1.1566443434308385e-06, 'ğŸ²': 1.1566443434308385e-06, 'ğŸ«': 8.09651040401587e-06, 'ğŸ¥”': 1.1566443434308385e-06, 'â˜‰': 1.1566443434308385e-06, 'â˜': 1.1566443434308385e-06, 'â˜…': 2.313288686861677e-06, 'â™›': 1.1566443434308385e-06, 'ğŸŒŒ': 1.1566443434308385e-06, 'ğŸ’': 1.1566443434308385e-06, '\\x80': 2.313288686861677e-06, 'â—': 1.1566443434308385e-06, 'ğŸˆ': 1.1566443434308385e-06, 'ğŸ™‰': 5.783221717154192e-06, 'ğŸ¨': 1.1566443434308385e-06, 'ğŸ™Š': 1.1566443434308385e-06, 'Ò¯': 1.1566443434308385e-06, 'ï¼¤': 1.1566443434308385e-06, 'à¼º': 2.313288686861677e-06, 'â˜¾': 2.313288686861677e-06, 'âœ­': 2.313288686861677e-06, 'â˜½': 2.313288686861677e-06, 'à¼»': 2.313288686861677e-06, 'ï¼­': 1.1566443434308385e-06, 'ï¼¶': 1.1566443434308385e-06, 'ğŸ’§': 1.1566443434308385e-06, 'ğŸ¤': 1.1566443434308385e-06, 'ğŸ˜ ': 5.783221717154192e-06, 'ğŸ”': 1.1566443434308385e-06, 'ğŸ¹': 1.1566443434308385e-06, 'ğŸ‡·': 1.1566443434308385e-06, 'â˜®': 1.1566443434308385e-06, 'âœ': 1.1566443434308385e-06, 'ğŸ‰': 1.1566443434308385e-06, 'â–ˆ': 1.619302080803174e-05, 'â•š': 1.1566443434308385e-06, 'â•©': 1.7349665151462578e-05, 'â•': 1.1566443434308385e-06, 'â™¬': 1.1566443434308385e-06, 'â˜¼': 2.313288686861677e-06, 'ì˜¤': 1.1566443434308385e-06, 'ëŠ˜': 1.1566443434308385e-06, 'ì˜': 1.1566443434308385e-06, 'ğŸ”Œ': 1.1566443434308385e-06, 'ğŸ’': 1.1566443434308385e-06, 'ğŸ': 1.1566443434308385e-06, 'â™«': 2.313288686861677e-06, 'ğŸ±': 1.1566443434308385e-06, 'ã€': 1.1566443434308385e-06, 'ã€‘': 1.1566443434308385e-06, 'ğŸ¸': 2.313288686861677e-06, 'ğŸ¹': 1.1566443434308385e-06, 'âšœ': 1.1566443434308385e-06, 'ğŸ•Š': 5.783221717154192e-06, 'ğŸ›´': 1.1566443434308385e-06, 'ğŸ’©': 1.1566443434308385e-06, '<unk>': 0.0005543237250554324}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3\n",
        "Implement the function *eval* that returns the perplexity of a model (dictionary) running over the data file of the given target language."
      ],
      "metadata": {
        "id": "xwZnk7Ke8rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calc_prob(model, n_gram, suffix, vocabulary_size, n):\n",
        "  if n == 1:\n",
        "    if n_gram not in model:\n",
        "      if '<unk>' in model: # smoothed\n",
        "        prob = model['<unk>']\n",
        "      else:\n",
        "        return 0\n",
        "    else:\n",
        "      prob = model[n_gram]\n",
        "\n",
        "  elif n_gram in model.keys() and suffix in model[n_gram]:\n",
        "    prob = model[n_gram][suffix]\n",
        "  elif '<unk>' in model: # smoothed\n",
        "    prob = model['<unk>']\n",
        "  else:\n",
        "    return 0 # not smoothed\n",
        "\n",
        "  return math.log(prob, 2)\n",
        "\n",
        "def eval(model: dict, target_lang: str, n: int) -> float:\n",
        "  '''\n",
        "  Return the perplexity value calculated over applying the model on the text file\n",
        "  of the target_lang language.\n",
        "  :param model: the language model\n",
        "  :param target_lang: the target language\n",
        "  :return: the perplexity value\n",
        "  '''\n",
        "  perplexities = []\n",
        "  vocabulary_lang = set()\n",
        "  file_path = os.path.join('/content/data', f'{target_lang}.json')\n",
        "  tweet_texts = get_tweet_texts(file_path)\n",
        "  for tweet in tweet_texts:\n",
        "    vocabulary_lang.update(tweet)\n",
        "  vocabulary_lang = list(vocabulary_lang)\n",
        "  vocabulary_size = len(vocabulary_lang)\n",
        "\n",
        "  for tweet in tweet_texts:\n",
        "    total_log_prob = 0\n",
        "    tweet = \"×\" * (n-1) + tweet + \"×ª\"\n",
        "    N = len(tweet) - n\n",
        "\n",
        "    for i in range(N-1):\n",
        "      if n == 1:\n",
        "        n_gram = tweet[i]\n",
        "      else:\n",
        "        n_gram = tweet[i:i+n-1]\n",
        "      suffix = tweet[i+n-1]\n",
        "      total_log_prob += calc_prob(model, n_gram, suffix, vocabulary_size, n)\n",
        "\n",
        "    perplexities.append(2 ** (-total_log_prob / N))\n",
        "\n",
        "  return sum(perplexities) / len(perplexities)\n",
        "\n",
        "# round(eval(lm('en', 1, True), 'en', 1))"
      ],
      "metadata": {
        "id": "ef-EglxXrmk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a8f7cd-ff43-4994-c117-fbc969730632"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4\n",
        "Implement the *match* function that calls *eval* using a specific value of *n* for every possible language pair among the languages we have data for. You should call *eval* for every language pair four times, with each call assign a different value for *n* (1-4). Each language pair is composed of the source language and the target language. Before you make the call, you need to call the *lm* function to create the language model for the source language. Then you can call *eval* with the language model and the target language. The function should return a pandas DataFrame with the following four columns: *source_lang*, *target_lang*, *n*, *perplexity*. The values for the first two columns are the two-letter language codes. The value for *n* is the *n* you use for generating the specific perplexity values which you should store in the forth column."
      ],
      "metadata": {
        "id": "9ZYVc7hB84LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match() -> pd.DataFrame:\n",
        "  '''\n",
        "  Return a DataFrame containing one line per every language pair and n_gram.\n",
        "  Each line will contain the perplexity calculated when applying the language model\n",
        "  of the source language on the text of the target language.\n",
        "  :return: a DataFrame containing the perplexity values\n",
        "  '''\n",
        "  results = []\n",
        "  files_list = list(filter(lambda f: f.endswith('.json'), os.listdir('/content/data')))\n",
        "  lang_list = list(map(lambda f: f[:-5], files_list))\n",
        "\n",
        "  for source in lang_list:\n",
        "    for n in range(1,5):\n",
        "      model = lm(source, n, True)\n",
        "\n",
        "\n",
        "      for target in lang_list:\n",
        "          perplexity = eval(model, target, n)\n",
        "          results.append({\n",
        "              'source': source,\n",
        "              'target': target,\n",
        "              'n': n,\n",
        "              'perplexity': perplexity\n",
        "          })\n",
        "\n",
        "  return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "match()"
      ],
      "metadata": {
        "id": "16ew9aZWroPC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "7b6fe523-ec66-4175-9b12-02e068b721f5"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-62415dd01f53>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-143-62415dd01f53>\u001b[0m in \u001b[0;36mmatch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlang_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m           \u001b[0mperplexity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m           results.append({\n\u001b[1;32m     20\u001b[0m               \u001b[0;34m'source'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-95ab874adc28>\u001b[0m in \u001b[0;36meval\u001b[0;34m(model, target_lang, n)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mn_gram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0mtotal_log_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mperplexities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtotal_log_prob\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-142-95ab874adc28>\u001b[0m in \u001b[0;36mcalc_prob\u001b[0;34m(model, n_gram, suffix, vocabulary_size, n)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;31m# not smoothed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lang\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5\n",
        "Implement the *generate* function which takes a language code, *n*, the prompt (the starting text), the number of tokens to generate, and *r*, which is the random seed for any randomized action you plan to take in your implementation. The function should start generating tokens, one by one, using the language model of the given source language and *n*. The prompt should be used as a starting point for aligning on the probabilities to be used for generating the next token.\n",
        "\n",
        "Note - The generation of the next token should be from the LM's distribution."
      ],
      "metadata": {
        "id": "pAQoR0dH9C3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def sample_from_dist(tokens, probs):\n",
        "    # Calculate the cumulative probability\n",
        "    cum_prob = 0\n",
        "    cum_probabilities = []\n",
        "    for p in probs:\n",
        "        cum_prob += p\n",
        "        cum_probabilities.append(cum_prob)\n",
        "\n",
        "    # Draw a random number in [0, max(cum_probabilities)]\n",
        "    r = random.uniform(0, max(cum_probabilities))\n",
        "\n",
        "    # Find where the random number fits in the cumulative distribution\n",
        "    for i, cp in enumerate(cum_probabilities):\n",
        "        if r < cp:\n",
        "            chosen_char = tokens[i]\n",
        "            break\n",
        "\n",
        "    return chosen_char\n",
        "\n",
        "def generate(lang: str, n: int, prompt: str, number_of_tokens: int, r: int) -> str:\n",
        "  '''\n",
        "  Generate text in the given language using the given parameters.\n",
        "  :param lang: the language of the model\n",
        "  :param n: the n_gram value\n",
        "  :param prompt: the prompt to start the generation\n",
        "  :param number_of_tokens: the number of tokens to generate\n",
        "  :param r: the random seed to use\n",
        "  '''\n",
        "  text = prompt\n",
        "  model = lm(lang, n, True)\n",
        "  n_gram = prompt[-n+1:]\n",
        "\n",
        "  for _ in range(number_of_tokens):\n",
        "    if n == 1 :\n",
        "      distribution = model\n",
        "    else:\n",
        "      distribution = model[n_gram]\n",
        "    tokens = list(distribution.keys())\n",
        "    probs = list(distribution.values())\n",
        "    gen_char = sample_from_dist(tokens, probs)\n",
        "    text += gen_char\n",
        "\n",
        "    if text.endswith('×ª'):\n",
        "      break\n",
        "    n_gram = n_gram[1:]\n",
        "    n_gram += gen_char\n",
        "\n",
        "  return text\n",
        "\n",
        "\n",
        "generate('en', 4, \"I eat\", 20, 5)"
      ],
      "metadata": {
        "id": "CpCm24-RrpuA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61e2908e-0a53-490f-f613-5261664aef82"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I eatnight bilizayn: thro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6\n",
        "Play with your generate function, try to generate different texts in different language and various values of *n*. No need to submit anything of that."
      ],
      "metadata": {
        "id": "eUWX8Ugu9INH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0ykbMBzG9LWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JZTlc2ieruqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c67dda54-0276-4705-8184-a6f0a50ae206"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_02563371-b31b-40c3-bf71-ed58952d12f7\", \"results.json\", 912)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "q2jNlDISr9aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the content of the **tests.py** file from the repo and paste below. This will create the results.json file and download it to your machine."
      ],
      "metadata": {
        "id": "uv48OCT_sIYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the local files, results.json should be there now and\n",
        "# also downloaded to your local machine\n",
        "####################\n",
        "# PLACE TESTS HERE #\n",
        "\n",
        "####################\n",
        "# Create tests\n",
        "\n",
        "\n",
        "# Create tests\n",
        "def test_preprocess():\n",
        "    return {\n",
        "        'vocab_length': len(preprocess()),\n",
        "    }\n",
        "\n",
        "def test_lm():\n",
        "    return {\n",
        "        'english_2_gram_length': len(lm('en', 2, True)),\n",
        "        'english_3_gram_length': len(lm('en', 3, True)),\n",
        "        'french_3_gram_length': len(lm('fr', 3, True)),\n",
        "        'spanish_3_gram_length': len(lm('es', 3, True)),\n",
        "    }\n",
        "\n",
        "def test_eval():\n",
        "    return {\n",
        "        'en_en': eval(lm('en', 3, True), 'en', 3),\n",
        "        'en_fr': eval(lm('en', 3, True), 'fr', 3),\n",
        "        'en_tl': eval(lm('en', 3, True), 'tl', 3),\n",
        "        'en_nl': eval(lm('en', 3, True), 'nl', 3),\n",
        "    }\n",
        "\n",
        "def test_match():\n",
        "    df = match()\n",
        "    return {\n",
        "        'en_en_3': df[(df['source'] == 'en') & (df['target'] == 'en') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_tl_3': df[(df['source'] == 'en') & (df['target'] == 'tl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_nl_3': df[(df['source'] == 'en') & (df['target'] == 'nl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "    }\n",
        "\n",
        "def test_generate():\n",
        "    return {\n",
        "        'english_1_gram': generate('en', 1, \"I\", 20, 5),\n",
        "        'english_2_gram': generate('en', 2, \"I am\", 20, 5),\n",
        "        'english_3_gram': generate('en', 3, \"I am\", 20, 5),\n",
        "        'english_4_gram': generate('en', 4, \"I Love\", 20, 5),\n",
        "        'spanish_2_gram': generate('es', 2, \"Soy\", 20, 5),\n",
        "        'spanish_3_gram': generate('es', 3, \"Soy\", 20, 5),\n",
        "        'french_2_gram': generate('fr', 2, \"Je suis\", 20, 5),\n",
        "        'french_3_gram': generate('fr', 3, \"Je suis\", 20, 5),\n",
        "    }\n",
        "\n",
        "TESTS = [test_preprocess, test_lm, test_eval, test_match, test_generate]\n",
        "\n",
        "# Run tests and save results\n",
        "res = {}\n",
        "for test in TESTS:\n",
        "    try:\n",
        "        cur_res = test()\n",
        "        res.update({test.__name__: cur_res})\n",
        "    except Exception as e:\n",
        "        res.update({test.__name__: repr(e)})\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(res, f, indent=2)\n",
        "\n",
        "# Download the results.json file\n",
        "files.download('results.json')\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "kCksAA6RisRQ",
        "outputId": "92a6a40c-ff55-4f76-b479-b6b60a2182c2"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2ffcb544-8e3c-4543-afcd-e86c4bedbd8d\", \"results.json\", 942)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 3 root root 4096 Apr 16 12:06 data\n",
            "-rw-r--r-- 1 root root  942 Apr 16 13:23 results.json\n",
            "drwxr-xr-x 1 root root 4096 Apr 12 13:22 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMSfgUtuiux0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}